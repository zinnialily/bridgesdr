Objective
This part of the project investigates the potential evaluation bias in synthetic disaster imagery models, focusing on how damage predictions differ between high-income countries (HICs) and low- and middle-income countries (LMICs). Specifically, it aims to answer the question:
    How does the predicted vs actual damage mask or SAR image comparison differ for HIC versus LMIC countries, and is the model conservative in its damage estimation?

Method Summary
Two predictive methods are evaluated:
1) Baseline Method - Predicted damage masks are generated by directly comparing the synthetic post-disaster optical image (output of DisasterGAN) with the pre-disaster image.
2) SAR-like Method - The synthetic post-disaster optical image is first converted into a SAR-like version. The damage mask is then computed by comparing this SAR-like image with the pre-disaster image.

In both cases, the output is a pixel-wise damage mask. These predicted masks are compared with an actual SAR post-disaster image-derived mask using pixel-level difference heuristics.

Evaluation metrics used:
    Intersection over Union (IoU)
    Dice coefficient
    Precision
    Recall

Geographic Comparison Procedure
    Each test tile is geolocated using metadata and manually classified as belonging to either a high-income (HIC) or low/middle-income (LMIC) region.

Performance metrics are computed and aggregated separately for: HIC regions and LMIC regions

Observations


Why Pixelated Damage Masks Are Used:
    1) Data Compatibility - The BRIGHT dataset primarily provides SAR post-disaster imagery and not building-level polygon annotations. Since the DisasterGAN pipeline generates pixel-space outputs, a pixel-wise mask provides a more direct comparison.
    
    2) Modal Mismatch - Most existing building damage classifiers are trained on optical imagery, often with high spatial resolution and building footprint annotations. These tools do not generalize well to SAR or synthetic images, making them poorly suited for this projectâ€™s SAR-based evaluation.
    
    3) Label Availability - While datasets like xBD contain building-level annotations, they are typically not aligned with SAR imagery. This makes it difficult to directly use such classifiers for the post-SAR comparisons in this project.
    
    4) Flexibility and Scale - Pixelated damage masks offer a resolution-agnostic way to assess performance across tiles without requiring consistent building detection quality. This is especially helpful when experimenting with large-scale satellite imagery or coarse SAR tiles in LMIC regions.
    
    5) Proxy Metric for Early Testing- Although pixel-wise differencing is a simplistic approach, it allows early-stage analysis of where and how the GAN output deviates from reality. It acts as a proxy to identify gaps in representation before attempting more complex semantic segmentation.

