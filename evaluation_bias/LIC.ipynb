{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64a04d2-8cad-419b-a6b1-703dca04e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered pre-event files matching LIC: 196\n",
      "Number of expected post-event files generated: 196\n",
      "Number of existing post-event files found: 196\n",
      "Number of matched pre/post pairs: 196\n",
      "Perfect 1:1 correspondence found between pre and post event files.\n"
     ]
    }
   ],
   "source": [
    "#Current goal: Save all the pairs of (pre,post) here for LIC and run the codes\n",
    "import os\n",
    "\n",
    "low_income = ['congo', 'haiti']\n",
    "pre_event_dir = r\"C:\\Users\\sweta\\Downloads\\pre-event\\pre-event_wo_ukraine_myanmar_mexico\"\n",
    "post_event_dir = r\"C:\\Users\\sweta\\Downloads\\post-event\\post-event\"\n",
    "\n",
    "all_pre_files = os.listdir(pre_event_dir)\n",
    "filtered_pre_files = [f for f in all_pre_files if any(country.lower() in f.lower() for country in low_income)]\n",
    "expected_post_files = [f.replace('_pre_disaster', '_post_disaster') for f in filtered_pre_files]\n",
    "all_post_files = os.listdir(post_event_dir)\n",
    "existing_post_files = [f for f in expected_post_files if f in all_post_files]\n",
    "\n",
    "pairs = []\n",
    "for pre_file, post_file in zip(filtered_pre_files, expected_post_files):\n",
    "    if post_file in all_post_files:\n",
    "        pairs.append((os.path.join(pre_event_dir, pre_file), os.path.join(post_event_dir, post_file)))\n",
    "#----Output---\n",
    "print(f\"Number of filtered pre-event files matching LIC: {len(filtered_pre_files)}\")\n",
    "print(f\"Number of expected post-event files generated: {len(expected_post_files)}\")\n",
    "print(f\"Number of existing post-event files found: {len(existing_post_files)}\")\n",
    "print(f\"Number of matched pre/post pairs: {len(pairs)}\")\n",
    "\n",
    "if len(filtered_pre_files) == len(existing_post_files) == len(pairs):\n",
    "    print(\"Perfect 1:1 correspondence found between pre and post event files.\")\n",
    "else:\n",
    "    print(\"Mismatch detected between pre and post event files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6df5ea-c425-4510-bae0-ca431eeb2b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Generator Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\AppData\\Local\\Temp\\ipykernel_8872\\1320358088.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\saved_models\\G_final.pth\", map_location=config.device))\n"
     ]
    }
   ],
   "source": [
    "#just need for sanity\n",
    "#all imports\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "#----\n",
    "#Configuration\n",
    "#----\n",
    "class Config:\n",
    "    seed = 42\n",
    "    img_size = 256\n",
    "    batch_size = 16\n",
    "    epochs = 10  # 10-epoch training\n",
    "    lr = 2e-4\n",
    "    betas = (0.5, 0.999)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Base loss weights (dynamically adjusted)\n",
    "    lambda_cls = 1\n",
    "    lambda_mask = 10\n",
    "    lambda_gp = 10\n",
    "    lambda_cycle = 10\n",
    "    \n",
    "    # Paths - updated for your local Windows system\n",
    "    data_root = r\"C:\\Users\\sweta\\.cache\\kagglehub\\datasets\\qianlanzz\\xbd-dataset\\versions\\1\\xbd\"\n",
    "    save_dir = r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\saved_models\"\n",
    "    samples_dir = r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\samples\"\n",
    "    plots_dir = r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\plots\"\n",
    "    \n",
    "    disaster_types = [\n",
    "        'volcano', 'fire', 'tornado', 'tsunami',\n",
    "        'flooding', 'earthquake', 'hurricane'\n",
    "    ]\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "os.makedirs(config.samples_dir, exist_ok=True)\n",
    "os.makedirs(config.plots_dir, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Dataset Implementation\n",
    "# -------------------------\n",
    "class XBDDataset(Dataset):\n",
    "    def __init__(self, split_names=(\"train\", \"tier1\", \"tier3\")):\n",
    "        self.pairs = []\n",
    "        for split in split_names:\n",
    "            split_path = os.path.join(config.data_root, split)\n",
    "            images_dir = os.path.join(split_path, \"images\")\n",
    "            labels_dir = os.path.join(split_path, \"labels\")\n",
    "            \n",
    "            pre_images = glob.glob(os.path.join(images_dir, \"*_pre_disaster.png\"))\n",
    "            for pre_path in pre_images:\n",
    "                base = os.path.basename(pre_path).replace(\"_pre_disaster.png\", \"\")\n",
    "                post_path = os.path.join(images_dir, f\"{base}_post_disaster.png\")\n",
    "                label_path = os.path.join(labels_dir, f\"{base}_post_disaster.json\")\n",
    "                \n",
    "                if os.path.exists(post_path):\n",
    "                    self.pairs.append({\n",
    "                        \"pre\": pre_path,\n",
    "                        \"post\": post_path,\n",
    "                        \"label\": label_path if os.path.exists(label_path) else None\n",
    "                    })\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(config.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def parse_disaster(self, label_path):\n",
    "        try:\n",
    "            with open(label_path) as f:\n",
    "                data = json.load(f)\n",
    "            disaster = data['metadata']['disaster_type']\n",
    "            return torch.tensor(config.disaster_types.index(disaster), dtype=torch.long)\n",
    "        except:\n",
    "            return torch.tensor(0, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        pre_img = self.transform(Image.open(pair[\"pre\"]).convert('RGB'))\n",
    "        post_img = self.transform(Image.open(pair[\"post\"]).convert('RGB'))\n",
    "        disaster_label = self.parse_disaster(pair[\"label\"])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            diff = torch.abs(post_img - pre_img).mean(dim=0, keepdim=True)\n",
    "            mask = (diff > 0.1).float()\n",
    "        \n",
    "        return {\n",
    "            'pre': pre_img,\n",
    "            'post': post_img,\n",
    "            'disaster': disaster_label,\n",
    "            'mask': mask\n",
    "        }\n",
    "\n",
    "# -------------------------\n",
    "# Generator Network\n",
    "# -------------------------\n",
    "class DisasterGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(4, 64, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.enc3 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(128, 256, 4, 2, 1)),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.enc4 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(256, 512, 4, 2, 1)),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # Decoders\n",
    "        self.dec_img = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.dec_mask = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def add_disaster_channel(self, x, disaster):\n",
    "        batch_size, _, h, w = x.size()\n",
    "        disaster_map = disaster.view(-1, 1, 1, 1).expand(-1, -1, h, w).float() / len(config.disaster_types)\n",
    "        return torch.cat([x, disaster_map], dim=1)\n",
    "\n",
    "    def forward(self, x, disaster):\n",
    "        x = self.add_disaster_channel(x, disaster)\n",
    "        \n",
    "        # Encoding\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        \n",
    "        # Decoding\n",
    "        img = self.dec_img(e4)\n",
    "        mask = self.dec_mask(e4)\n",
    "        return img, mask\n",
    "\n",
    "# -------------------------\n",
    "# Discriminator Network\n",
    "# -------------------------\n",
    "class DisasterDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(3, 64, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Conv2d(128, 256, 4, 2, 1)),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Conv2d(256, 512, 4, 2, 1)),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.src = spectral_norm(nn.Conv2d(512, 1, 4, 1, 1))\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            spectral_norm(nn.Conv2d(512, len(config.disaster_types), 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.main(x)\n",
    "        return self.src(features), self.cls(features)\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize generator model\n",
    "G = DisasterGenerator().to(config.device)\n",
    "\n",
    "# Load trained weights\n",
    "G.load_state_dict(torch.load(r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\saved_models\\G_final.pth\", map_location=config.device))\n",
    "\n",
    "# Set to evaluation mode\n",
    "G.eval()\n",
    "\n",
    "print(\"Loaded Generator Model\")\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "transform_rgb = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ac78c9-be27-4e10-bb35-6ef16dc8e3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pair 1/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.585\n",
      "  Dice: 0.603\n",
      "  F1: 0.603\n",
      "  Precision: 0.612\n",
      "  Recall: 0.596\n",
      "\n",
      "=== Pair 2/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.889\n",
      "  Dice: 0.935\n",
      "  F1: 0.935\n",
      "  Precision: 0.973\n",
      "  Recall: 0.907\n",
      "\n",
      "=== Pair 3/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.964\n",
      "  Dice: 0.981\n",
      "  F1: 0.981\n",
      "  Precision: 0.989\n",
      "  Recall: 0.974\n",
      "\n",
      "=== Pair 4/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.951\n",
      "  Dice: 0.974\n",
      "  F1: 0.974\n",
      "  Precision: 0.978\n",
      "  Recall: 0.972\n",
      "\n",
      "=== Pair 5/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.966\n",
      "  Dice: 0.983\n",
      "  F1: 0.983\n",
      "  Precision: 0.992\n",
      "  Recall: 0.974\n",
      "\n",
      "=== Pair 6/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.944\n",
      "  Dice: 0.970\n",
      "  F1: 0.970\n",
      "  Precision: 0.983\n",
      "  Recall: 0.958\n",
      "\n",
      "=== Pair 7/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.931\n",
      "  Dice: 0.962\n",
      "  F1: 0.962\n",
      "  Precision: 0.986\n",
      "  Recall: 0.943\n",
      "\n",
      "=== Pair 8/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.930\n",
      "  Dice: 0.963\n",
      "  F1: 0.963\n",
      "  Precision: 0.979\n",
      "  Recall: 0.949\n",
      "\n",
      "=== Pair 9/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.689\n",
      "  Dice: 0.754\n",
      "  F1: 0.754\n",
      "  Precision: 0.772\n",
      "  Recall: 0.839\n",
      "\n",
      "=== Pair 10/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.612\n",
      "  Dice: 0.666\n",
      "  F1: 0.666\n",
      "  Precision: 0.699\n",
      "  Recall: 0.648\n",
      "\n",
      "=== Pair 11/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.204\n",
      "  Dice: 0.250\n",
      "  F1: 0.250\n",
      "  Precision: 0.322\n",
      "  Recall: 0.237\n",
      "\n",
      "=== Pair 12/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.549\n",
      "  Dice: 0.583\n",
      "  F1: 0.583\n",
      "  Precision: 0.607\n",
      "  Recall: 0.623\n",
      "\n",
      "=== Pair 13/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.852\n",
      "  Dice: 0.911\n",
      "  F1: 0.911\n",
      "  Precision: 0.965\n",
      "  Recall: 0.874\n",
      "\n",
      "=== Pair 14/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.769\n",
      "  Dice: 0.861\n",
      "  F1: 0.861\n",
      "  Precision: 0.946\n",
      "  Recall: 0.798\n",
      "\n",
      "=== Pair 15/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.836\n",
      "  Dice: 0.905\n",
      "  F1: 0.905\n",
      "  Precision: 0.957\n",
      "  Recall: 0.863\n",
      "\n",
      "=== Pair 16/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.950\n",
      "  Dice: 0.974\n",
      "  F1: 0.974\n",
      "  Precision: 0.985\n",
      "  Recall: 0.963\n",
      "\n",
      "=== Pair 17/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.925\n",
      "  Dice: 0.960\n",
      "  F1: 0.960\n",
      "  Precision: 0.981\n",
      "  Recall: 0.941\n",
      "\n",
      "=== Pair 18/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.888\n",
      "  Dice: 0.938\n",
      "  F1: 0.938\n",
      "  Precision: 0.965\n",
      "  Recall: 0.916\n",
      "\n",
      "=== Pair 19/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.920\n",
      "  Dice: 0.954\n",
      "  F1: 0.954\n",
      "  Precision: 0.982\n",
      "  Recall: 0.934\n",
      "\n",
      "=== Pair 20/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.838\n",
      "  Dice: 0.906\n",
      "  F1: 0.906\n",
      "  Precision: 0.963\n",
      "  Recall: 0.863\n",
      "\n",
      "=== Pair 21/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.801\n",
      "  Dice: 0.884\n",
      "  F1: 0.884\n",
      "  Precision: 0.952\n",
      "  Recall: 0.832\n",
      "\n",
      "=== Pair 22/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.691\n",
      "  Dice: 0.793\n",
      "  F1: 0.793\n",
      "  Precision: 0.886\n",
      "  Recall: 0.743\n",
      "\n",
      "=== Pair 23/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.326\n",
      "  Dice: 0.379\n",
      "  F1: 0.379\n",
      "  Precision: 0.461\n",
      "  Recall: 0.340\n",
      "\n",
      "=== Pair 24/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.602\n",
      "  Dice: 0.669\n",
      "  F1: 0.669\n",
      "  Precision: 0.716\n",
      "  Recall: 0.666\n",
      "\n",
      "=== Pair 25/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.603\n",
      "  Dice: 0.745\n",
      "  F1: 0.745\n",
      "  Precision: 0.882\n",
      "  Recall: 0.656\n",
      "\n",
      "=== Pair 26/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.597\n",
      "  Dice: 0.727\n",
      "  F1: 0.727\n",
      "  Precision: 0.882\n",
      "  Recall: 0.639\n",
      "\n",
      "=== Pair 27/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.787\n",
      "  Dice: 0.869\n",
      "  F1: 0.869\n",
      "  Precision: 0.947\n",
      "  Recall: 0.816\n",
      "\n",
      "=== Pair 28/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.894\n",
      "  Dice: 0.942\n",
      "  F1: 0.942\n",
      "  Precision: 0.973\n",
      "  Recall: 0.916\n",
      "\n",
      "=== Pair 29/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.929\n",
      "  Dice: 0.963\n",
      "  F1: 0.963\n",
      "  Precision: 0.982\n",
      "  Recall: 0.944\n",
      "\n",
      "=== Pair 30/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.878\n",
      "  Dice: 0.934\n",
      "  F1: 0.934\n",
      "  Precision: 0.975\n",
      "  Recall: 0.897\n",
      "\n",
      "=== Pair 31/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.853\n",
      "  Dice: 0.918\n",
      "  F1: 0.918\n",
      "  Precision: 0.970\n",
      "  Recall: 0.874\n",
      "\n",
      "=== Pair 32/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.920\n",
      "  Dice: 0.956\n",
      "  F1: 0.956\n",
      "  Precision: 0.978\n",
      "  Recall: 0.939\n",
      "\n",
      "=== Pair 33/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.919\n",
      "  Dice: 0.957\n",
      "  F1: 0.957\n",
      "  Precision: 0.982\n",
      "  Recall: 0.935\n",
      "\n",
      "=== Pair 34/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.903\n",
      "  Dice: 0.947\n",
      "  F1: 0.947\n",
      "  Precision: 0.971\n",
      "  Recall: 0.927\n",
      "\n",
      "=== Pair 35/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.713\n",
      "  Dice: 0.822\n",
      "  F1: 0.822\n",
      "  Precision: 0.925\n",
      "  Recall: 0.752\n",
      "\n",
      "=== Pair 36/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.357\n",
      "  Dice: 0.406\n",
      "  F1: 0.406\n",
      "  Precision: 0.452\n",
      "  Recall: 0.383\n",
      "\n",
      "=== Pair 37/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.439\n",
      "  Dice: 0.496\n",
      "  F1: 0.496\n",
      "  Precision: 0.577\n",
      "  Recall: 0.462\n",
      "\n",
      "=== Pair 38/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.414\n",
      "  Dice: 0.575\n",
      "  F1: 0.575\n",
      "  Precision: 0.848\n",
      "  Recall: 0.456\n",
      "\n",
      "=== Pair 39/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.421\n",
      "  Dice: 0.582\n",
      "  F1: 0.582\n",
      "  Precision: 0.866\n",
      "  Recall: 0.454\n",
      "\n",
      "=== Pair 40/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.496\n",
      "  Dice: 0.636\n",
      "  F1: 0.636\n",
      "  Precision: 0.884\n",
      "  Recall: 0.526\n",
      "\n",
      "=== Pair 41/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.874\n",
      "  Dice: 0.929\n",
      "  F1: 0.929\n",
      "  Precision: 0.979\n",
      "  Recall: 0.888\n",
      "\n",
      "=== Pair 42/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.831\n",
      "  Dice: 0.885\n",
      "  F1: 0.885\n",
      "  Precision: 0.954\n",
      "  Recall: 0.849\n",
      "\n",
      "=== Pair 43/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.766\n",
      "  Dice: 0.849\n",
      "  F1: 0.849\n",
      "  Precision: 0.949\n",
      "  Recall: 0.790\n",
      "\n",
      "=== Pair 44/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.806\n",
      "  Dice: 0.883\n",
      "  F1: 0.883\n",
      "  Precision: 0.947\n",
      "  Recall: 0.840\n",
      "\n",
      "=== Pair 45/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.934\n",
      "  Dice: 0.966\n",
      "  F1: 0.966\n",
      "  Precision: 0.969\n",
      "  Recall: 0.963\n",
      "\n",
      "=== Pair 46/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.867\n",
      "  Dice: 0.920\n",
      "  F1: 0.920\n",
      "  Precision: 0.974\n",
      "  Recall: 0.884\n",
      "\n",
      "=== Pair 47/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.911\n",
      "  Dice: 0.952\n",
      "  F1: 0.952\n",
      "  Precision: 0.975\n",
      "  Recall: 0.932\n",
      "\n",
      "=== Pair 48/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.700\n",
      "  Dice: 0.804\n",
      "  F1: 0.804\n",
      "  Precision: 0.935\n",
      "  Recall: 0.729\n",
      "\n",
      "=== Pair 49/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.308\n",
      "  Dice: 0.370\n",
      "  F1: 0.370\n",
      "  Precision: 0.449\n",
      "  Recall: 0.325\n",
      "\n",
      "=== Pair 50/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.403\n",
      "  Dice: 0.480\n",
      "  F1: 0.480\n",
      "  Precision: 0.550\n",
      "  Recall: 0.434\n",
      "\n",
      "=== Pair 51/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.507\n",
      "  Dice: 0.664\n",
      "  F1: 0.664\n",
      "  Precision: 0.853\n",
      "  Recall: 0.560\n",
      "\n",
      "=== Pair 52/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.497\n",
      "  Dice: 0.646\n",
      "  F1: 0.646\n",
      "  Precision: 0.885\n",
      "  Recall: 0.524\n",
      "\n",
      "=== Pair 53/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.710\n",
      "  Dice: 0.808\n",
      "  F1: 0.808\n",
      "  Precision: 0.940\n",
      "  Recall: 0.731\n",
      "\n",
      "=== Pair 54/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.672\n",
      "  Dice: 0.777\n",
      "  F1: 0.777\n",
      "  Precision: 0.928\n",
      "  Recall: 0.697\n",
      "\n",
      "=== Pair 55/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.608\n",
      "  Dice: 0.735\n",
      "  F1: 0.735\n",
      "  Precision: 0.899\n",
      "  Recall: 0.643\n",
      "\n",
      "=== Pair 56/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.571\n",
      "  Dice: 0.704\n",
      "  F1: 0.704\n",
      "  Precision: 0.918\n",
      "  Recall: 0.600\n",
      "\n",
      "=== Pair 57/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.929\n",
      "  Dice: 0.962\n",
      "  F1: 0.962\n",
      "  Precision: 0.976\n",
      "  Recall: 0.950\n",
      "\n",
      "=== Pair 58/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.895\n",
      "  Dice: 0.943\n",
      "  F1: 0.943\n",
      "  Precision: 0.955\n",
      "  Recall: 0.933\n",
      "\n",
      "=== Pair 59/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.818\n",
      "  Dice: 0.880\n",
      "  F1: 0.880\n",
      "  Precision: 0.935\n",
      "  Recall: 0.850\n",
      "\n",
      "=== Pair 60/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.448\n",
      "  Dice: 0.600\n",
      "  F1: 0.600\n",
      "  Precision: 0.911\n",
      "  Recall: 0.465\n",
      "\n",
      "=== Pair 61/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.403\n",
      "  Dice: 0.443\n",
      "  F1: 0.443\n",
      "  Precision: 0.460\n",
      "  Recall: 0.432\n",
      "\n",
      "=== Pair 62/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.410\n",
      "  Dice: 0.487\n",
      "  F1: 0.487\n",
      "  Precision: 0.570\n",
      "  Recall: 0.436\n",
      "\n",
      "=== Pair 63/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.524\n",
      "  Dice: 0.675\n",
      "  F1: 0.675\n",
      "  Precision: 0.848\n",
      "  Recall: 0.578\n",
      "\n",
      "=== Pair 64/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.423\n",
      "  Dice: 0.582\n",
      "  F1: 0.582\n",
      "  Precision: 0.848\n",
      "  Recall: 0.455\n",
      "\n",
      "=== Pair 65/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.492\n",
      "  Dice: 0.639\n",
      "  F1: 0.639\n",
      "  Precision: 0.870\n",
      "  Recall: 0.527\n",
      "\n",
      "=== Pair 66/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.689\n",
      "  Dice: 0.774\n",
      "  F1: 0.774\n",
      "  Precision: 0.927\n",
      "  Recall: 0.717\n",
      "\n",
      "=== Pair 67/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.413\n",
      "  Dice: 0.576\n",
      "  F1: 0.576\n",
      "  Precision: 0.909\n",
      "  Recall: 0.432\n",
      "\n",
      "=== Pair 68/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.811\n",
      "  Dice: 0.883\n",
      "  F1: 0.883\n",
      "  Precision: 0.948\n",
      "  Recall: 0.838\n",
      "\n",
      "=== Pair 69/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.810\n",
      "  Dice: 0.869\n",
      "  F1: 0.869\n",
      "  Precision: 0.932\n",
      "  Recall: 0.845\n",
      "\n",
      "=== Pair 70/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.539\n",
      "  Dice: 0.677\n",
      "  F1: 0.677\n",
      "  Precision: 0.907\n",
      "  Recall: 0.567\n",
      "\n",
      "=== Pair 71/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.421\n",
      "  Dice: 0.568\n",
      "  F1: 0.568\n",
      "  Precision: 0.892\n",
      "  Recall: 0.438\n",
      "\n",
      "=== Pair 72/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.478\n",
      "  Dice: 0.488\n",
      "  F1: 0.488\n",
      "  Precision: 0.489\n",
      "  Recall: 0.488\n",
      "\n",
      "=== Pair 73/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.364\n",
      "  Dice: 0.439\n",
      "  F1: 0.439\n",
      "  Precision: 0.560\n",
      "  Recall: 0.390\n",
      "\n",
      "=== Pair 74/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.415\n",
      "  Dice: 0.570\n",
      "  F1: 0.570\n",
      "  Precision: 0.873\n",
      "  Recall: 0.439\n",
      "\n",
      "=== Pair 75/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.378\n",
      "  Dice: 0.546\n",
      "  F1: 0.546\n",
      "  Precision: 0.895\n",
      "  Recall: 0.397\n",
      "\n",
      "=== Pair 76/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.545\n",
      "  Dice: 0.674\n",
      "  F1: 0.674\n",
      "  Precision: 0.898\n",
      "  Recall: 0.580\n",
      "\n",
      "=== Pair 77/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.504\n",
      "  Dice: 0.664\n",
      "  F1: 0.664\n",
      "  Precision: 0.928\n",
      "  Recall: 0.525\n",
      "\n",
      "=== Pair 78/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.531\n",
      "  Dice: 0.673\n",
      "  F1: 0.673\n",
      "  Precision: 0.912\n",
      "  Recall: 0.556\n",
      "\n",
      "=== Pair 79/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.510\n",
      "  Dice: 0.653\n",
      "  F1: 0.653\n",
      "  Precision: 0.915\n",
      "  Recall: 0.530\n",
      "\n",
      "=== Pair 80/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.385\n",
      "  Dice: 0.546\n",
      "  F1: 0.546\n",
      "  Precision: 0.889\n",
      "  Recall: 0.404\n",
      "\n",
      "=== Pair 81/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.572\n",
      "  Dice: 0.682\n",
      "  F1: 0.682\n",
      "  Precision: 0.896\n",
      "  Recall: 0.602\n",
      "\n",
      "=== Pair 82/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.467\n",
      "  Dice: 0.482\n",
      "  F1: 0.482\n",
      "  Precision: 0.487\n",
      "  Recall: 0.478\n",
      "\n",
      "=== Pair 83/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.397\n",
      "  Dice: 0.473\n",
      "  F1: 0.473\n",
      "  Precision: 0.558\n",
      "  Recall: 0.429\n",
      "\n",
      "=== Pair 84/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.451\n",
      "  Dice: 0.618\n",
      "  F1: 0.618\n",
      "  Precision: 0.899\n",
      "  Recall: 0.474\n",
      "\n",
      "=== Pair 85/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.494\n",
      "  Dice: 0.658\n",
      "  F1: 0.658\n",
      "  Precision: 0.913\n",
      "  Recall: 0.517\n",
      "\n",
      "=== Pair 86/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.546\n",
      "  Dice: 0.702\n",
      "  F1: 0.702\n",
      "  Precision: 0.940\n",
      "  Recall: 0.564\n",
      "\n",
      "=== Pair 87/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.422\n",
      "  Dice: 0.586\n",
      "  F1: 0.586\n",
      "  Precision: 0.911\n",
      "  Recall: 0.440\n",
      "\n",
      "=== Pair 88/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.415\n",
      "  Dice: 0.575\n",
      "  F1: 0.575\n",
      "  Precision: 0.898\n",
      "  Recall: 0.438\n",
      "\n",
      "=== Pair 89/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.353\n",
      "  Dice: 0.519\n",
      "  F1: 0.519\n",
      "  Precision: 0.863\n",
      "  Recall: 0.375\n",
      "\n",
      "=== Pair 90/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.342\n",
      "  Dice: 0.489\n",
      "  F1: 0.489\n",
      "  Precision: 0.854\n",
      "  Recall: 0.366\n",
      "\n",
      "=== Pair 91/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.362\n",
      "  Dice: 0.406\n",
      "  F1: 0.406\n",
      "  Precision: 0.449\n",
      "  Recall: 0.392\n",
      "\n",
      "=== Pair 92/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.355\n",
      "  Dice: 0.451\n",
      "  F1: 0.451\n",
      "  Precision: 0.568\n",
      "  Recall: 0.440\n",
      "\n",
      "=== Pair 93/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.543\n",
      "  Dice: 0.703\n",
      "  F1: 0.703\n",
      "  Precision: 0.932\n",
      "  Recall: 0.565\n",
      "\n",
      "=== Pair 94/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.602\n",
      "  Dice: 0.748\n",
      "  F1: 0.748\n",
      "  Precision: 0.948\n",
      "  Recall: 0.622\n",
      "\n",
      "=== Pair 95/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.509\n",
      "  Dice: 0.674\n",
      "  F1: 0.674\n",
      "  Precision: 0.910\n",
      "  Recall: 0.536\n",
      "\n",
      "=== Pair 96/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.364\n",
      "  Dice: 0.528\n",
      "  F1: 0.528\n",
      "  Precision: 0.893\n",
      "  Recall: 0.382\n",
      "\n",
      "=== Pair 97/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.369\n",
      "  Dice: 0.537\n",
      "  F1: 0.537\n",
      "  Precision: 0.920\n",
      "  Recall: 0.381\n",
      "\n",
      "=== Pair 98/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.348\n",
      "  Dice: 0.512\n",
      "  F1: 0.512\n",
      "  Precision: 0.875\n",
      "  Recall: 0.367\n",
      "\n",
      "=== Pair 99/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.160\n",
      "  Dice: 0.238\n",
      "  F1: 0.238\n",
      "  Precision: 0.407\n",
      "  Recall: 0.181\n",
      "\n",
      "=== Pair 100/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.405\n",
      "  Dice: 0.506\n",
      "  F1: 0.506\n",
      "  Precision: 0.608\n",
      "  Recall: 0.524\n",
      "\n",
      "=== Pair 101/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.582\n",
      "  Dice: 0.735\n",
      "  F1: 0.735\n",
      "  Precision: 0.937\n",
      "  Recall: 0.606\n",
      "\n",
      "=== Pair 102/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.561\n",
      "  Dice: 0.717\n",
      "  F1: 0.717\n",
      "  Precision: 0.924\n",
      "  Recall: 0.589\n",
      "\n",
      "=== Pair 103/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.532\n",
      "  Dice: 0.688\n",
      "  F1: 0.688\n",
      "  Precision: 0.931\n",
      "  Recall: 0.556\n",
      "\n",
      "=== Pair 104/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.446\n",
      "  Dice: 0.614\n",
      "  F1: 0.614\n",
      "  Precision: 0.935\n",
      "  Recall: 0.460\n",
      "\n",
      "=== Pair 105/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.335\n",
      "  Dice: 0.499\n",
      "  F1: 0.499\n",
      "  Precision: 0.913\n",
      "  Recall: 0.346\n",
      "\n",
      "=== Pair 106/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.227\n",
      "  Dice: 0.289\n",
      "  F1: 0.289\n",
      "  Precision: 0.435\n",
      "  Recall: 0.242\n",
      "\n",
      "=== Pair 107/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.453\n",
      "  Dice: 0.578\n",
      "  F1: 0.578\n",
      "  Precision: 0.764\n",
      "  Recall: 0.533\n",
      "\n",
      "=== Pair 108/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.556\n",
      "  Dice: 0.705\n",
      "  F1: 0.705\n",
      "  Precision: 0.918\n",
      "  Recall: 0.583\n",
      "\n",
      "=== Pair 109/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.495\n",
      "  Dice: 0.656\n",
      "  F1: 0.656\n",
      "  Precision: 0.909\n",
      "  Recall: 0.523\n",
      "\n",
      "=== Pair 110/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.411\n",
      "  Dice: 0.579\n",
      "  F1: 0.579\n",
      "  Precision: 0.902\n",
      "  Recall: 0.430\n",
      "\n",
      "=== Pair 111/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.353\n",
      "  Dice: 0.514\n",
      "  F1: 0.514\n",
      "  Precision: 0.905\n",
      "  Recall: 0.372\n",
      "\n",
      "=== Pair 112/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.250\n",
      "  Dice: 0.319\n",
      "  F1: 0.319\n",
      "  Precision: 0.395\n",
      "  Recall: 0.295\n",
      "\n",
      "=== Pair 113/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.466\n",
      "  Dice: 0.599\n",
      "  F1: 0.599\n",
      "  Precision: 0.755\n",
      "  Recall: 0.554\n",
      "\n",
      "=== Pair 114/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.404\n",
      "  Dice: 0.564\n",
      "  F1: 0.564\n",
      "  Precision: 0.859\n",
      "  Recall: 0.436\n",
      "\n",
      "=== Pair 115/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.605\n",
      "  Dice: 0.742\n",
      "  F1: 0.742\n",
      "  Precision: 0.921\n",
      "  Recall: 0.638\n",
      "\n",
      "=== Pair 116/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.563\n",
      "  Dice: 0.686\n",
      "  F1: 0.686\n",
      "  Precision: 0.891\n",
      "  Recall: 0.596\n",
      "\n",
      "=== Pair 117/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.368\n",
      "  Dice: 0.394\n",
      "  F1: 0.394\n",
      "  Precision: 0.399\n",
      "  Recall: 0.393\n",
      "\n",
      "=== Pair 118/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.102\n",
      "  Dice: 0.132\n",
      "  F1: 0.132\n",
      "  Precision: 0.170\n",
      "  Recall: 0.108\n",
      "\n",
      "=== Pair 119/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.475\n",
      "  Dice: 0.618\n",
      "  F1: 0.618\n",
      "  Precision: 0.865\n",
      "  Recall: 0.500\n",
      "\n",
      "=== Pair 120/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.757\n",
      "  Dice: 0.846\n",
      "  F1: 0.846\n",
      "  Precision: 0.938\n",
      "  Recall: 0.794\n",
      "\n",
      "=== Pair 121/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.503\n",
      "  Dice: 0.547\n",
      "  F1: 0.547\n",
      "  Precision: 0.562\n",
      "  Recall: 0.552\n",
      "\n",
      "=== Pair 122/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.113\n",
      "  Dice: 0.140\n",
      "  F1: 0.140\n",
      "  Precision: 0.167\n",
      "  Recall: 0.122\n",
      "\n",
      "=== Pair 123/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.296\n",
      "  Dice: 0.333\n",
      "  F1: 0.333\n",
      "  Precision: 0.353\n",
      "  Recall: 0.424\n",
      "\n",
      "=== Pair 124/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.775\n",
      "  Dice: 0.871\n",
      "  F1: 0.871\n",
      "  Precision: 0.901\n",
      "  Recall: 0.847\n",
      "\n",
      "=== Pair 125/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.579\n",
      "  Dice: 0.667\n",
      "  F1: 0.667\n",
      "  Precision: 0.718\n",
      "  Recall: 0.627\n",
      "\n",
      "=== Pair 126/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.409\n",
      "  Dice: 0.491\n",
      "  F1: 0.491\n",
      "  Precision: 0.517\n",
      "  Recall: 0.483\n",
      "\n",
      "=== Pair 127/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.384\n",
      "  Dice: 0.407\n",
      "  F1: 0.407\n",
      "  Precision: 0.403\n",
      "  Recall: 0.417\n",
      "\n",
      "=== Pair 128/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.763\n",
      "  Dice: 0.864\n",
      "  F1: 0.864\n",
      "  Precision: 0.920\n",
      "  Recall: 0.816\n",
      "\n",
      "=== Pair 129/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.767\n",
      "  Dice: 0.867\n",
      "  F1: 0.867\n",
      "  Precision: 0.912\n",
      "  Recall: 0.828\n",
      "\n",
      "=== Pair 130/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.756\n",
      "  Dice: 0.860\n",
      "  F1: 0.860\n",
      "  Precision: 0.922\n",
      "  Recall: 0.808\n",
      "\n",
      "=== Pair 131/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.824\n",
      "  Dice: 0.901\n",
      "  F1: 0.901\n",
      "  Precision: 0.936\n",
      "  Recall: 0.869\n",
      "\n",
      "=== Pair 132/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.709\n",
      "  Dice: 0.827\n",
      "  F1: 0.827\n",
      "  Precision: 0.863\n",
      "  Recall: 0.798\n",
      "\n",
      "=== Pair 133/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.743\n",
      "  Dice: 0.849\n",
      "  F1: 0.849\n",
      "  Precision: 0.873\n",
      "  Recall: 0.836\n",
      "\n",
      "=== Pair 134/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.585\n",
      "  Dice: 0.676\n",
      "  F1: 0.676\n",
      "  Precision: 0.704\n",
      "  Recall: 0.662\n",
      "\n",
      "=== Pair 135/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.429\n",
      "  Dice: 0.490\n",
      "  F1: 0.490\n",
      "  Precision: 0.514\n",
      "  Recall: 0.522\n",
      "\n",
      "=== Pair 136/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.284\n",
      "  Dice: 0.325\n",
      "  F1: 0.325\n",
      "  Precision: 0.339\n",
      "  Recall: 0.366\n",
      "\n",
      "=== Pair 137/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.750\n",
      "  Dice: 0.856\n",
      "  F1: 0.856\n",
      "  Precision: 0.916\n",
      "  Recall: 0.805\n",
      "\n",
      "=== Pair 138/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.791\n",
      "  Dice: 0.883\n",
      "  F1: 0.883\n",
      "  Precision: 0.920\n",
      "  Recall: 0.848\n",
      "\n",
      "=== Pair 139/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.797\n",
      "  Dice: 0.887\n",
      "  F1: 0.887\n",
      "  Precision: 0.931\n",
      "  Recall: 0.846\n",
      "\n",
      "=== Pair 140/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.733\n",
      "  Dice: 0.841\n",
      "  F1: 0.841\n",
      "  Precision: 0.914\n",
      "  Recall: 0.784\n",
      "\n",
      "=== Pair 141/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.672\n",
      "  Dice: 0.800\n",
      "  F1: 0.800\n",
      "  Precision: 0.870\n",
      "  Recall: 0.744\n",
      "\n",
      "=== Pair 142/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.747\n",
      "  Dice: 0.854\n",
      "  F1: 0.854\n",
      "  Precision: 0.886\n",
      "  Recall: 0.825\n",
      "\n",
      "=== Pair 143/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.610\n",
      "  Dice: 0.754\n",
      "  F1: 0.754\n",
      "  Precision: 0.823\n",
      "  Recall: 0.703\n",
      "\n",
      "=== Pair 144/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.692\n",
      "  Dice: 0.813\n",
      "  F1: 0.813\n",
      "  Precision: 0.877\n",
      "  Recall: 0.763\n",
      "\n",
      "=== Pair 145/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.677\n",
      "  Dice: 0.800\n",
      "  F1: 0.800\n",
      "  Precision: 0.869\n",
      "  Recall: 0.750\n",
      "\n",
      "=== Pair 146/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.767\n",
      "  Dice: 0.866\n",
      "  F1: 0.866\n",
      "  Precision: 0.918\n",
      "  Recall: 0.822\n",
      "\n",
      "=== Pair 147/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.727\n",
      "  Dice: 0.840\n",
      "  F1: 0.840\n",
      "  Precision: 0.877\n",
      "  Recall: 0.812\n",
      "\n",
      "=== Pair 148/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.806\n",
      "  Dice: 0.892\n",
      "  F1: 0.892\n",
      "  Precision: 0.932\n",
      "  Recall: 0.857\n",
      "\n",
      "=== Pair 149/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.812\n",
      "  Dice: 0.896\n",
      "  F1: 0.896\n",
      "  Precision: 0.935\n",
      "  Recall: 0.860\n",
      "\n",
      "=== Pair 150/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.794\n",
      "  Dice: 0.883\n",
      "  F1: 0.883\n",
      "  Precision: 0.912\n",
      "  Recall: 0.859\n",
      "\n",
      "=== Pair 151/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.722\n",
      "  Dice: 0.836\n",
      "  F1: 0.836\n",
      "  Precision: 0.873\n",
      "  Recall: 0.810\n",
      "\n",
      "=== Pair 152/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.744\n",
      "  Dice: 0.850\n",
      "  F1: 0.850\n",
      "  Precision: 0.877\n",
      "  Recall: 0.833\n",
      "\n",
      "=== Pair 153/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.733\n",
      "  Dice: 0.838\n",
      "  F1: 0.838\n",
      "  Precision: 0.871\n",
      "  Recall: 0.812\n",
      "\n",
      "=== Pair 154/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.586\n",
      "  Dice: 0.730\n",
      "  F1: 0.730\n",
      "  Precision: 0.830\n",
      "  Recall: 0.664\n",
      "\n",
      "=== Pair 155/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.777\n",
      "  Dice: 0.874\n",
      "  F1: 0.874\n",
      "  Precision: 0.918\n",
      "  Recall: 0.835\n",
      "\n",
      "=== Pair 156/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.781\n",
      "  Dice: 0.877\n",
      "  F1: 0.877\n",
      "  Precision: 0.932\n",
      "  Recall: 0.828\n",
      "\n",
      "=== Pair 157/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.808\n",
      "  Dice: 0.893\n",
      "  F1: 0.893\n",
      "  Precision: 0.933\n",
      "  Recall: 0.859\n",
      "\n",
      "=== Pair 158/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.764\n",
      "  Dice: 0.864\n",
      "  F1: 0.864\n",
      "  Precision: 0.913\n",
      "  Recall: 0.822\n",
      "\n",
      "=== Pair 159/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.801\n",
      "  Dice: 0.888\n",
      "  F1: 0.888\n",
      "  Precision: 0.914\n",
      "  Recall: 0.865\n",
      "\n",
      "=== Pair 160/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.740\n",
      "  Dice: 0.847\n",
      "  F1: 0.847\n",
      "  Precision: 0.894\n",
      "  Recall: 0.810\n",
      "\n",
      "=== Pair 161/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.793\n",
      "  Dice: 0.882\n",
      "  F1: 0.882\n",
      "  Precision: 0.928\n",
      "  Recall: 0.842\n",
      "\n",
      "=== Pair 162/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.616\n",
      "  Dice: 0.755\n",
      "  F1: 0.755\n",
      "  Precision: 0.850\n",
      "  Recall: 0.694\n",
      "\n",
      "=== Pair 163/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.709\n",
      "  Dice: 0.824\n",
      "  F1: 0.824\n",
      "  Precision: 0.869\n",
      "  Recall: 0.791\n",
      "\n",
      "=== Pair 164/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.769\n",
      "  Dice: 0.868\n",
      "  F1: 0.868\n",
      "  Precision: 0.920\n",
      "  Recall: 0.824\n",
      "\n",
      "=== Pair 165/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.760\n",
      "  Dice: 0.862\n",
      "  F1: 0.862\n",
      "  Precision: 0.924\n",
      "  Recall: 0.811\n",
      "\n",
      "=== Pair 166/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.786\n",
      "  Dice: 0.879\n",
      "  F1: 0.879\n",
      "  Precision: 0.933\n",
      "  Recall: 0.832\n",
      "\n",
      "=== Pair 167/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.806\n",
      "  Dice: 0.889\n",
      "  F1: 0.889\n",
      "  Precision: 0.936\n",
      "  Recall: 0.854\n",
      "\n",
      "=== Pair 168/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.738\n",
      "  Dice: 0.846\n",
      "  F1: 0.846\n",
      "  Precision: 0.879\n",
      "  Recall: 0.824\n",
      "\n",
      "=== Pair 169/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.665\n",
      "  Dice: 0.795\n",
      "  F1: 0.795\n",
      "  Precision: 0.854\n",
      "  Recall: 0.749\n",
      "\n",
      "=== Pair 170/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.760\n",
      "  Dice: 0.830\n",
      "  F1: 0.830\n",
      "  Precision: 0.844\n",
      "  Recall: 0.824\n",
      "\n",
      "=== Pair 171/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.728\n",
      "  Dice: 0.841\n",
      "  F1: 0.841\n",
      "  Precision: 0.877\n",
      "  Recall: 0.813\n",
      "\n",
      "=== Pair 172/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.804\n",
      "  Dice: 0.890\n",
      "  F1: 0.890\n",
      "  Precision: 0.933\n",
      "  Recall: 0.853\n",
      "\n",
      "=== Pair 173/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.728\n",
      "  Dice: 0.839\n",
      "  F1: 0.839\n",
      "  Precision: 0.904\n",
      "  Recall: 0.787\n",
      "\n",
      "=== Pair 174/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.778\n",
      "  Dice: 0.875\n",
      "  F1: 0.875\n",
      "  Precision: 0.925\n",
      "  Recall: 0.830\n",
      "\n",
      "=== Pair 175/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.811\n",
      "  Dice: 0.893\n",
      "  F1: 0.893\n",
      "  Precision: 0.952\n",
      "  Recall: 0.843\n",
      "\n",
      "=== Pair 176/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.819\n",
      "  Dice: 0.900\n",
      "  F1: 0.900\n",
      "  Precision: 0.954\n",
      "  Recall: 0.852\n",
      "\n",
      "=== Pair 177/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.764\n",
      "  Dice: 0.863\n",
      "  F1: 0.863\n",
      "  Precision: 0.929\n",
      "  Recall: 0.810\n",
      "\n",
      "=== Pair 178/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.592\n",
      "  Dice: 0.714\n",
      "  F1: 0.714\n",
      "  Precision: 0.719\n",
      "  Recall: 0.775\n",
      "\n",
      "=== Pair 179/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.799\n",
      "  Dice: 0.885\n",
      "  F1: 0.885\n",
      "  Precision: 0.918\n",
      "  Recall: 0.858\n",
      "\n",
      "=== Pair 180/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.755\n",
      "  Dice: 0.858\n",
      "  F1: 0.858\n",
      "  Precision: 0.901\n",
      "  Recall: 0.823\n",
      "\n",
      "=== Pair 181/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.754\n",
      "  Dice: 0.858\n",
      "  F1: 0.858\n",
      "  Precision: 0.926\n",
      "  Recall: 0.801\n",
      "\n",
      "=== Pair 182/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.758\n",
      "  Dice: 0.859\n",
      "  F1: 0.859\n",
      "  Precision: 0.906\n",
      "  Recall: 0.820\n",
      "\n",
      "=== Pair 183/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.731\n",
      "  Dice: 0.832\n",
      "  F1: 0.832\n",
      "  Precision: 0.865\n",
      "  Recall: 0.839\n",
      "\n",
      "=== Pair 184/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.699\n",
      "  Dice: 0.800\n",
      "  F1: 0.800\n",
      "  Precision: 0.821\n",
      "  Recall: 0.850\n",
      "\n",
      "=== Pair 185/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.676\n",
      "  Dice: 0.782\n",
      "  F1: 0.782\n",
      "  Precision: 0.790\n",
      "  Recall: 0.804\n",
      "\n",
      "=== Pair 186/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.722\n",
      "  Dice: 0.826\n",
      "  F1: 0.826\n",
      "  Precision: 0.870\n",
      "  Recall: 0.802\n",
      "\n",
      "=== Pair 187/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.768\n",
      "  Dice: 0.867\n",
      "  F1: 0.867\n",
      "  Precision: 0.870\n",
      "  Recall: 0.871\n",
      "\n",
      "=== Pair 188/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.751\n",
      "  Dice: 0.854\n",
      "  F1: 0.854\n",
      "  Precision: 0.904\n",
      "  Recall: 0.815\n",
      "\n",
      "=== Pair 189/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.749\n",
      "  Dice: 0.853\n",
      "  F1: 0.853\n",
      "  Precision: 0.925\n",
      "  Recall: 0.794\n",
      "\n",
      "=== Pair 190/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.728\n",
      "  Dice: 0.837\n",
      "  F1: 0.837\n",
      "  Precision: 0.910\n",
      "  Recall: 0.781\n",
      "\n",
      "=== Pair 191/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.603\n",
      "  Dice: 0.731\n",
      "  F1: 0.731\n",
      "  Precision: 0.753\n",
      "  Recall: 0.750\n",
      "\n",
      "=== Pair 192/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.738\n",
      "  Dice: 0.846\n",
      "  F1: 0.846\n",
      "  Precision: 0.864\n",
      "  Recall: 0.837\n",
      "\n",
      "=== Pair 193/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.740\n",
      "  Dice: 0.849\n",
      "  F1: 0.849\n",
      "  Precision: 0.864\n",
      "  Recall: 0.840\n",
      "\n",
      "=== Pair 194/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.694\n",
      "  Dice: 0.803\n",
      "  F1: 0.803\n",
      "  Precision: 0.901\n",
      "  Recall: 0.740\n",
      "\n",
      "=== Pair 195/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.546\n",
      "  Dice: 0.603\n",
      "  F1: 0.603\n",
      "  Precision: 0.589\n",
      "  Recall: 0.630\n",
      "\n",
      "=== Pair 196/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.362\n",
      "  Dice: 0.414\n",
      "  F1: 0.414\n",
      "  Precision: 0.405\n",
      "  Recall: 0.430\n",
      "\n",
      "=== Overall Summary Across All Pairs ===\n",
      "Average IoU: 0.633\n",
      "Median IoU: 0.689\n",
      "Average Dice: 0.730\n",
      "Median Dice: 0.797\n",
      "Average F1: 0.730\n",
      "Median F1: 0.797\n",
      "Average Precision: 0.835\n",
      "Median Precision: 0.904\n",
      "Average Recall: 0.678\n",
      "Median Recall: 0.749\n",
      "Saved results for disaster 'earthquake' to C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\\earthquake\n",
      "Saved results for disaster 'volcano' to C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\\volcano\n",
      "\n",
      "Saved all results to: C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Model setup\n",
    "device = config.device\n",
    "G.eval()\n",
    "\n",
    "disaster_types = ['earthquake', 'flood', 'hurricane', 'fire', 'tsunami', 'volcano']\n",
    "\n",
    "# Disaster label inference\n",
    "def infer_disaster_type(filename):\n",
    "    for d in disaster_types:\n",
    "        if d in filename.lower():\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "transform_rgb = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "transform_gray = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def tensor_to_pil(tensor):\n",
    "    \"\"\"\n",
    "    Convert a normalized tensor (C,H,W) with values in [-1,1] to a PIL RGB image.\n",
    "    \"\"\"\n",
    "    tensor = tensor.squeeze(0).cpu()  # Remove batch dim, move to CPU\n",
    "    tensor = (tensor * 0.5) + 0.5     # Denormalize from [-1,1] to [0,1]\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    np_img = tensor.permute(1, 2, 0).numpy() * 255\n",
    "    np_img = np_img.astype(np.uint8)\n",
    "    return Image.fromarray(np_img)\n",
    "\n",
    "\n",
    "# SAR mask function\n",
    "def SAR_damage_mask(pre_optical_img, post_sar_img, threshold=0.1):\n",
    "    def optical_to_sar_like(img):\n",
    "        img = img.convert('L')\n",
    "        img = ImageOps.autocontrast(img, cutoff=2)\n",
    "        return img\n",
    "\n",
    "    pre_sar_like = optical_to_sar_like(pre_optical_img)\n",
    "    post_sar = post_sar_img.convert('L')\n",
    "\n",
    "    pre_tensor = transform_gray(pre_sar_like).to(device)\n",
    "    post_tensor = transform_gray(post_sar).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        diff = torch.abs(post_tensor - pre_tensor).unsqueeze(0)\n",
    "        diff = F.avg_pool2d(diff, kernel_size=3, stride=1, padding=1)\n",
    "        img_std = diff.std()\n",
    "        adaptive_threshold = threshold + (0.1 * img_std)\n",
    "        mask = (diff > adaptive_threshold).float()\n",
    "        mask = F.max_pool2d(mask, kernel_size=3, stride=1, padding=1)\n",
    "        mask = F.avg_pool2d(mask, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    return mask.squeeze(0)\n",
    "\n",
    "# Metric calculation\n",
    "def compute_mask_metrics(pred_mask, true_mask):\n",
    "    pred = pred_mask.flatten().cpu().numpy().astype(int)\n",
    "    true = true_mask.flatten().cpu().numpy().astype(int)\n",
    "    return {\n",
    "        'IoU': jaccard_score(true, pred),\n",
    "        'Dice': f1_score(true, pred),\n",
    "        'F1': f1_score(true, pred),\n",
    "        'Precision': precision_score(true, pred),\n",
    "        'Recall': recall_score(true, pred)\n",
    "    }\n",
    "\n",
    "# 95% Confidence Interval function\n",
    "def compute_ci(arr):\n",
    "    mean = np.mean(arr)\n",
    "    std_err = np.std(arr) / np.sqrt(len(arr))\n",
    "    return (mean - 1.96 * std_err, mean + 1.96 * std_err)\n",
    "\n",
    "# Get all pre-post pairs\n",
    "low_income = ['congo', 'haiti']\n",
    "pre_event_dir = r\"C:\\Users\\sweta\\Downloads\\pre-event\\pre-event_wo_ukraine_myanmar_mexico\"\n",
    "post_event_dir = r\"C:\\Users\\sweta\\Downloads\\post-event\\post-event\"\n",
    "all_pre_files = os.listdir(pre_event_dir)\n",
    "filtered_pre_files = [f for f in all_pre_files if any(country.lower() in f.lower() for country in low_income)]\n",
    "expected_post_files = [f.replace('_pre_disaster', '_post_disaster') for f in filtered_pre_files]\n",
    "all_post_files = os.listdir(post_event_dir)\n",
    "pairs = [\n",
    "    (os.path.join(pre_event_dir, pre), os.path.join(post_event_dir, post))\n",
    "    for pre, post in zip(filtered_pre_files, expected_post_files)\n",
    "    if post in all_post_files\n",
    "]\n",
    "\n",
    "# Output directories setup\n",
    "output_dir = r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "disaster_output_dirs = {}\n",
    "for d in disaster_types:\n",
    "    dir_path = os.path.join(output_dir, d)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    disaster_output_dirs[d] = dir_path\n",
    "\n",
    "# Evaluation loop\n",
    "all_pair_metrics = []\n",
    "disaster_type_metrics = {d: [] for d in disaster_types}\n",
    "\n",
    "for pair_idx, (pre_path, post_path) in enumerate(pairs):\n",
    "    print(f\"\\n=== Pair {pair_idx+1}/{len(pairs)} ===\")\n",
    "    pre_img_full = Image.open(pre_path).convert('RGB')\n",
    "    post_img_full = Image.open(post_path).convert('RGB')\n",
    "\n",
    "    tile_size = 256\n",
    "    width, height = pre_img_full.size\n",
    "    tiles = []\n",
    "\n",
    "    for top in range(0, height, tile_size):\n",
    "        for left in range(0, width, tile_size):\n",
    "            box = (left, top, left + tile_size, top + tile_size)\n",
    "            if box[2] <= width and box[3] <= height:\n",
    "                pre_tile = pre_img_full.crop(box)\n",
    "                post_tile = post_img_full.crop(box)\n",
    "                tiles.append((pre_tile, post_tile))\n",
    "\n",
    "    tile_metrics = []\n",
    "\n",
    "    for idx, (pre_img, post_img) in enumerate(tiles):\n",
    "        input_tensor = transform_rgb(pre_img).unsqueeze(0).to(device)\n",
    "        post_resized = post_img.resize((256, 256))\n",
    "\n",
    "        inferred_type = infer_disaster_type(pre_path)\n",
    "        if inferred_type is None:\n",
    "            print(f\"Unknown disaster type for file: {pre_path}\")\n",
    "            continue\n",
    "\n",
    "        disaster_idx = disaster_types.index(inferred_type)\n",
    "        disaster_label = torch.tensor([[disaster_idx]], device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_post, pred_mask = G(input_tensor, disaster_label)\n",
    "        actual_mask = SAR_damage_mask(pre_img, post_resized, threshold=0.2)\n",
    "        fake_post_img = tensor_to_pil(fake_post)\n",
    "        pred_mask = SAR_damage_mask(pre_img, fake_post_img, threshold=0.2)\n",
    "        metrics = compute_mask_metrics(pred_mask[0], actual_mask[0])\n",
    "        tile_metrics.append(metrics)\n",
    "\n",
    "        # Save visualization every 10th tile\n",
    "        if idx % 10 == 0:\n",
    "            vis_dir = os.path.join(disaster_output_dirs[inferred_type], \"visualizations\")\n",
    "            os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "            axs[0].imshow(pre_img)\n",
    "            axs[0].set_title(\"Pre-disaster\")\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            axs[1].imshow(post_img)\n",
    "            axs[1].set_title(\"Post-disaster (True)\")\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            axs[2].imshow(fake_post_img)\n",
    "            axs[2].set_title(\"Fake Post (Generated)\")\n",
    "            axs[2].axis('off')\n",
    "\n",
    "            axs[3].imshow(pred_mask[0].cpu(), cmap='gray')\n",
    "            axs[3].set_title(\"Predicted Damage Mask\")\n",
    "            axs[3].axis('off')\n",
    "\n",
    "            plt.suptitle(f\"Pair {pair_idx+1}, Tile {idx} ({inferred_type})\")\n",
    "            save_path = os.path.join(vis_dir, f\"pair{pair_idx+1}_tile{idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'IoU': np.mean([m['IoU'] for m in tile_metrics]),\n",
    "        'Dice': np.mean([m['Dice'] for m in tile_metrics]),\n",
    "        'F1': np.mean([m['F1'] for m in tile_metrics]),\n",
    "        'Precision': np.mean([m['Precision'] for m in tile_metrics]),\n",
    "        'Recall': np.mean([m['Recall'] for m in tile_metrics]),\n",
    "    }\n",
    "    all_pair_metrics.append({\n",
    "        'pair': (os.path.basename(pre_path), os.path.basename(post_path)),\n",
    "        'metrics': mean_metrics\n",
    "    })\n",
    "    disaster_type_metrics[inferred_type].append(mean_metrics)\n",
    "\n",
    "    print(\"Mean metrics for this pair:\")\n",
    "    for k, v in mean_metrics.items():\n",
    "        print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "# Overall stats\n",
    "print(\"\\n=== Overall Summary Across All Pairs ===\")\n",
    "all_iou = [m['metrics']['IoU'] for m in all_pair_metrics]\n",
    "all_dice = [m['metrics']['Dice'] for m in all_pair_metrics]\n",
    "all_f1 = [m['metrics']['F1'] for m in all_pair_metrics]\n",
    "all_prec = [m['metrics']['Precision'] for m in all_pair_metrics]\n",
    "all_rec = [m['metrics']['Recall'] for m in all_pair_metrics]\n",
    "\n",
    "print(f\"Average IoU: {np.mean(all_iou):.3f}\")\n",
    "print(f\"Median IoU: {np.median(all_iou):.3f}\")\n",
    "print(f\"Average Dice: {np.mean(all_dice):.3f}\")\n",
    "print(f\"Median Dice: {np.median(all_dice):.3f}\")\n",
    "print(f\"Average F1: {np.mean(all_f1):.3f}\")\n",
    "print(f\"Median F1: {np.median(all_f1):.3f}\")\n",
    "print(f\"Average Precision: {np.mean(all_prec):.3f}\")\n",
    "print(f\"Median Precision: {np.median(all_prec):.3f}\")\n",
    "print(f\"Average Recall: {np.mean(all_rec):.3f}\")\n",
    "print(f\"Median Recall: {np.median(all_rec):.3f}\")\n",
    "\n",
    "# Save global results\n",
    "with open(os.path.join(output_dir, \"per_pair_metrics.json\"), \"w\") as f:\n",
    "    json.dump(all_pair_metrics, f, indent=2)\n",
    "\n",
    "summary_stats = {\n",
    "    'Average IoU': float(np.mean(all_iou)),\n",
    "    'Median IoU': float(np.median(all_iou)),\n",
    "    '95% CI IoU': list(compute_ci(all_iou)),\n",
    "\n",
    "    'Average Dice': float(np.mean(all_dice)),\n",
    "    'Median Dice': float(np.median(all_dice)),\n",
    "    '95% CI Dice': list(compute_ci(all_dice)),\n",
    "\n",
    "    'Average F1': float(np.mean(all_f1)),\n",
    "    'Median F1': float(np.median(all_f1)),\n",
    "    '95% CI F1': list(compute_ci(all_f1)),\n",
    "\n",
    "    'Average Precision': float(np.mean(all_prec)),\n",
    "    'Median Precision': float(np.median(all_prec)),\n",
    "    '95% CI Precision': list(compute_ci(all_prec)),\n",
    "\n",
    "    'Average Recall': float(np.mean(all_rec)),\n",
    "    'Median Recall': float(np.median(all_rec)),\n",
    "    '95% CI Recall': list(compute_ci(all_rec)),\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, \"summary_stats.json\"), \"w\") as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "# Save results per disaster type\n",
    "for d in disaster_types:\n",
    "    metrics_list = disaster_type_metrics[d]\n",
    "    if not metrics_list:\n",
    "        continue  # skip if no data for this disaster\n",
    "\n",
    "    iou_vals = [m['IoU'] for m in metrics_list]\n",
    "    dice_vals = [m['Dice'] for m in metrics_list]\n",
    "    f1_vals = [m['F1'] for m in metrics_list]\n",
    "    prec_vals = [m['Precision'] for m in metrics_list]\n",
    "    rec_vals = [m['Recall'] for m in metrics_list]\n",
    "\n",
    "    summary = {\n",
    "        'Average IoU': float(np.mean(iou_vals)),\n",
    "        'Median IoU': float(np.median(iou_vals)),\n",
    "        '95% CI IoU': list(compute_ci(iou_vals)),\n",
    "\n",
    "        'Average Dice': float(np.mean(dice_vals)),\n",
    "        'Median Dice': float(np.median(dice_vals)),\n",
    "        '95% CI Dice': list(compute_ci(dice_vals)),\n",
    "\n",
    "        'Average F1': float(np.mean(f1_vals)),\n",
    "        'Median F1': float(np.median(f1_vals)),\n",
    "        '95% CI F1': list(compute_ci(f1_vals)),\n",
    "\n",
    "        'Average Precision': float(np.mean(prec_vals)),\n",
    "        'Median Precision': float(np.median(prec_vals)),\n",
    "        '95% CI Precision': list(compute_ci(prec_vals)),\n",
    "\n",
    "        'Average Recall': float(np.mean(rec_vals)),\n",
    "        'Median Recall': float(np.median(rec_vals)),\n",
    "        '95% CI Recall': list(compute_ci(rec_vals)),\n",
    "    }\n",
    "\n",
    "    per_pair_path = os.path.join(disaster_output_dirs[d], f\"per_pair_metrics_{d}.json\")\n",
    "    summary_path = os.path.join(disaster_output_dirs[d], f\"summary_stats_{d}.json\")\n",
    "\n",
    "    disaster_pairs = [p for p in all_pair_metrics if infer_disaster_type(p['pair'][0]) == d]\n",
    "\n",
    "    with open(per_pair_path, 'w') as f:\n",
    "        json.dump(disaster_pairs, f, indent=2)\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"Saved results for disaster '{d}' to {disaster_output_dirs[d]}\")\n",
    "\n",
    "print(f\"\\nSaved all results to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ea1bf61-7b05-40d2-9d02-3cd9e1447229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred mask shape: torch.Size([1, 256, 256])\n",
      "Actual mask shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred mask shape:\", pred_mask.shape)\n",
    "print(\"Actual mask shape:\", actual_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3089c7c-0fcf-491e-9fda-412553b61913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pair 1/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.453\n",
      "  Dice: 0.509\n",
      "  F1: 0.509\n",
      "  Precision: 0.881\n",
      "  Recall: 0.511\n",
      "\n",
      "=== Pair 2/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.421\n",
      "  Dice: 0.575\n",
      "  F1: 0.575\n",
      "  Precision: 0.617\n",
      "  Recall: 0.591\n",
      "\n",
      "=== Pair 3/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.577\n",
      "  Dice: 0.705\n",
      "  F1: 0.705\n",
      "  Precision: 0.725\n",
      "  Recall: 0.719\n",
      "\n",
      "=== Pair 4/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.521\n",
      "  Dice: 0.660\n",
      "  F1: 0.660\n",
      "  Precision: 0.676\n",
      "  Recall: 0.676\n",
      "\n",
      "=== Pair 5/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.580\n",
      "  Dice: 0.709\n",
      "  F1: 0.709\n",
      "  Precision: 0.717\n",
      "  Recall: 0.717\n",
      "\n",
      "=== Pair 6/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.583\n",
      "  Dice: 0.710\n",
      "  F1: 0.710\n",
      "  Precision: 0.724\n",
      "  Recall: 0.718\n",
      "\n",
      "=== Pair 7/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.637\n",
      "  Dice: 0.755\n",
      "  F1: 0.755\n",
      "  Precision: 0.771\n",
      "  Recall: 0.758\n",
      "\n",
      "=== Pair 8/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.635\n",
      "  Dice: 0.752\n",
      "  F1: 0.752\n",
      "  Precision: 0.765\n",
      "  Recall: 0.756\n",
      "\n",
      "=== Pair 9/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.378\n",
      "  Dice: 0.498\n",
      "  F1: 0.498\n",
      "  Precision: 0.694\n",
      "  Recall: 0.501\n",
      "\n",
      "=== Pair 10/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.295\n",
      "  Dice: 0.400\n",
      "  F1: 0.400\n",
      "  Precision: 0.671\n",
      "  Recall: 0.414\n",
      "\n",
      "=== Pair 11/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.201\n",
      "  Dice: 0.252\n",
      "  F1: 0.252\n",
      "  Precision: 0.867\n",
      "  Recall: 0.244\n",
      "\n",
      "=== Pair 12/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.388\n",
      "  Dice: 0.464\n",
      "  F1: 0.464\n",
      "  Precision: 0.847\n",
      "  Recall: 0.460\n",
      "\n",
      "=== Pair 13/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.493\n",
      "  Dice: 0.643\n",
      "  F1: 0.643\n",
      "  Precision: 0.664\n",
      "  Recall: 0.653\n",
      "\n",
      "=== Pair 14/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.430\n",
      "  Dice: 0.587\n",
      "  F1: 0.587\n",
      "  Precision: 0.623\n",
      "  Recall: 0.587\n",
      "\n",
      "=== Pair 15/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.501\n",
      "  Dice: 0.648\n",
      "  F1: 0.648\n",
      "  Precision: 0.667\n",
      "  Recall: 0.653\n",
      "\n",
      "=== Pair 16/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.522\n",
      "  Dice: 0.675\n",
      "  F1: 0.675\n",
      "  Precision: 0.687\n",
      "  Recall: 0.678\n",
      "\n",
      "=== Pair 17/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.470\n",
      "  Dice: 0.631\n",
      "  F1: 0.631\n",
      "  Precision: 0.647\n",
      "  Recall: 0.633\n",
      "\n",
      "=== Pair 18/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.526\n",
      "  Dice: 0.677\n",
      "  F1: 0.677\n",
      "  Precision: 0.693\n",
      "  Recall: 0.679\n",
      "\n",
      "=== Pair 19/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.491\n",
      "  Dice: 0.645\n",
      "  F1: 0.645\n",
      "  Precision: 0.673\n",
      "  Recall: 0.650\n",
      "\n",
      "=== Pair 20/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.445\n",
      "  Dice: 0.594\n",
      "  F1: 0.594\n",
      "  Precision: 0.638\n",
      "  Recall: 0.596\n",
      "\n",
      "=== Pair 21/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.455\n",
      "  Dice: 0.608\n",
      "  F1: 0.608\n",
      "  Precision: 0.640\n",
      "  Recall: 0.603\n",
      "\n",
      "=== Pair 22/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.324\n",
      "  Dice: 0.468\n",
      "  F1: 0.468\n",
      "  Precision: 0.536\n",
      "  Recall: 0.468\n",
      "\n",
      "=== Pair 23/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.271\n",
      "  Dice: 0.332\n",
      "  F1: 0.332\n",
      "  Precision: 0.835\n",
      "  Recall: 0.326\n",
      "\n",
      "=== Pair 24/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.489\n",
      "  Dice: 0.580\n",
      "  F1: 0.580\n",
      "  Precision: 0.799\n",
      "  Recall: 0.580\n",
      "\n",
      "=== Pair 25/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.401\n",
      "  Dice: 0.555\n",
      "  F1: 0.555\n",
      "  Precision: 0.616\n",
      "  Recall: 0.543\n",
      "\n",
      "=== Pair 26/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.448\n",
      "  Dice: 0.596\n",
      "  F1: 0.596\n",
      "  Precision: 0.614\n",
      "  Recall: 0.597\n",
      "\n",
      "=== Pair 27/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.472\n",
      "  Dice: 0.628\n",
      "  F1: 0.628\n",
      "  Precision: 0.652\n",
      "  Recall: 0.627\n",
      "\n",
      "=== Pair 28/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.501\n",
      "  Dice: 0.653\n",
      "  F1: 0.653\n",
      "  Precision: 0.670\n",
      "  Recall: 0.660\n",
      "\n",
      "=== Pair 29/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.525\n",
      "  Dice: 0.677\n",
      "  F1: 0.677\n",
      "  Precision: 0.691\n",
      "  Recall: 0.681\n",
      "\n",
      "=== Pair 30/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.492\n",
      "  Dice: 0.643\n",
      "  F1: 0.643\n",
      "  Precision: 0.661\n",
      "  Recall: 0.641\n",
      "\n",
      "=== Pair 31/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.479\n",
      "  Dice: 0.635\n",
      "  F1: 0.635\n",
      "  Precision: 0.669\n",
      "  Recall: 0.636\n",
      "\n",
      "=== Pair 32/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.533\n",
      "  Dice: 0.683\n",
      "  F1: 0.683\n",
      "  Precision: 0.701\n",
      "  Recall: 0.687\n",
      "\n",
      "=== Pair 33/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.477\n",
      "  Dice: 0.628\n",
      "  F1: 0.628\n",
      "  Precision: 0.682\n",
      "  Recall: 0.616\n",
      "\n",
      "=== Pair 34/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.458\n",
      "  Dice: 0.614\n",
      "  F1: 0.614\n",
      "  Precision: 0.643\n",
      "  Recall: 0.613\n",
      "\n",
      "=== Pair 35/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.368\n",
      "  Dice: 0.514\n",
      "  F1: 0.514\n",
      "  Precision: 0.561\n",
      "  Recall: 0.502\n",
      "\n",
      "=== Pair 36/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.270\n",
      "  Dice: 0.338\n",
      "  F1: 0.338\n",
      "  Precision: 0.838\n",
      "  Recall: 0.329\n",
      "\n",
      "=== Pair 37/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.427\n",
      "  Dice: 0.491\n",
      "  F1: 0.491\n",
      "  Precision: 0.874\n",
      "  Recall: 0.492\n",
      "\n",
      "=== Pair 38/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.457\n",
      "  Dice: 0.607\n",
      "  F1: 0.607\n",
      "  Precision: 0.660\n",
      "  Recall: 0.589\n",
      "\n",
      "=== Pair 39/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.472\n",
      "  Dice: 0.619\n",
      "  F1: 0.619\n",
      "  Precision: 0.662\n",
      "  Recall: 0.604\n",
      "\n",
      "=== Pair 40/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.552\n",
      "  Dice: 0.691\n",
      "  F1: 0.691\n",
      "  Precision: 0.737\n",
      "  Recall: 0.669\n",
      "\n",
      "=== Pair 41/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.532\n",
      "  Dice: 0.683\n",
      "  F1: 0.683\n",
      "  Precision: 0.695\n",
      "  Recall: 0.684\n",
      "\n",
      "=== Pair 42/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.541\n",
      "  Dice: 0.690\n",
      "  F1: 0.690\n",
      "  Precision: 0.710\n",
      "  Recall: 0.682\n",
      "\n",
      "=== Pair 43/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.453\n",
      "  Dice: 0.607\n",
      "  F1: 0.607\n",
      "  Precision: 0.652\n",
      "  Recall: 0.610\n",
      "\n",
      "=== Pair 44/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.472\n",
      "  Dice: 0.628\n",
      "  F1: 0.628\n",
      "  Precision: 0.662\n",
      "  Recall: 0.626\n",
      "\n",
      "=== Pair 45/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.440\n",
      "  Dice: 0.597\n",
      "  F1: 0.597\n",
      "  Precision: 0.640\n",
      "  Recall: 0.604\n",
      "\n",
      "=== Pair 46/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.411\n",
      "  Dice: 0.560\n",
      "  F1: 0.560\n",
      "  Precision: 0.604\n",
      "  Recall: 0.567\n",
      "\n",
      "=== Pair 47/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.359\n",
      "  Dice: 0.511\n",
      "  F1: 0.511\n",
      "  Precision: 0.563\n",
      "  Recall: 0.515\n",
      "\n",
      "=== Pair 48/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.441\n",
      "  Dice: 0.591\n",
      "  F1: 0.591\n",
      "  Precision: 0.645\n",
      "  Recall: 0.577\n",
      "\n",
      "=== Pair 49/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.279\n",
      "  Dice: 0.348\n",
      "  F1: 0.348\n",
      "  Precision: 0.848\n",
      "  Recall: 0.342\n",
      "\n",
      "=== Pair 50/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.370\n",
      "  Dice: 0.441\n",
      "  F1: 0.441\n",
      "  Precision: 0.816\n",
      "  Recall: 0.428\n",
      "\n",
      "=== Pair 51/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.409\n",
      "  Dice: 0.558\n",
      "  F1: 0.558\n",
      "  Precision: 0.609\n",
      "  Recall: 0.541\n",
      "\n",
      "=== Pair 52/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.523\n",
      "  Dice: 0.670\n",
      "  F1: 0.670\n",
      "  Precision: 0.711\n",
      "  Recall: 0.650\n",
      "\n",
      "=== Pair 53/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.529\n",
      "  Dice: 0.679\n",
      "  F1: 0.679\n",
      "  Precision: 0.704\n",
      "  Recall: 0.667\n",
      "\n",
      "=== Pair 54/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.494\n",
      "  Dice: 0.647\n",
      "  F1: 0.647\n",
      "  Precision: 0.682\n",
      "  Recall: 0.637\n",
      "\n",
      "=== Pair 55/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.443\n",
      "  Dice: 0.598\n",
      "  F1: 0.598\n",
      "  Precision: 0.648\n",
      "  Recall: 0.584\n",
      "\n",
      "=== Pair 56/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.484\n",
      "  Dice: 0.637\n",
      "  F1: 0.637\n",
      "  Precision: 0.700\n",
      "  Recall: 0.616\n",
      "\n",
      "=== Pair 57/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.441\n",
      "  Dice: 0.599\n",
      "  F1: 0.599\n",
      "  Precision: 0.640\n",
      "  Recall: 0.611\n",
      "\n",
      "=== Pair 58/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.428\n",
      "  Dice: 0.585\n",
      "  F1: 0.585\n",
      "  Precision: 0.617\n",
      "  Recall: 0.595\n",
      "\n",
      "=== Pair 59/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.431\n",
      "  Dice: 0.584\n",
      "  F1: 0.584\n",
      "  Precision: 0.634\n",
      "  Recall: 0.589\n",
      "\n",
      "=== Pair 60/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.359\n",
      "  Dice: 0.504\n",
      "  F1: 0.504\n",
      "  Precision: 0.582\n",
      "  Recall: 0.488\n",
      "\n",
      "=== Pair 61/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.296\n",
      "  Dice: 0.364\n",
      "  F1: 0.364\n",
      "  Precision: 0.861\n",
      "  Recall: 0.356\n",
      "\n",
      "=== Pair 62/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.363\n",
      "  Dice: 0.443\n",
      "  F1: 0.443\n",
      "  Precision: 0.816\n",
      "  Recall: 0.438\n",
      "\n",
      "=== Pair 63/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.504\n",
      "  Dice: 0.649\n",
      "  F1: 0.649\n",
      "  Precision: 0.698\n",
      "  Recall: 0.625\n",
      "\n",
      "=== Pair 64/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.508\n",
      "  Dice: 0.653\n",
      "  F1: 0.653\n",
      "  Precision: 0.688\n",
      "  Recall: 0.636\n",
      "\n",
      "=== Pair 65/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.479\n",
      "  Dice: 0.627\n",
      "  F1: 0.627\n",
      "  Precision: 0.659\n",
      "  Recall: 0.615\n",
      "\n",
      "=== Pair 66/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.455\n",
      "  Dice: 0.613\n",
      "  F1: 0.613\n",
      "  Precision: 0.660\n",
      "  Recall: 0.608\n",
      "\n",
      "=== Pair 67/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.496\n",
      "  Dice: 0.647\n",
      "  F1: 0.647\n",
      "  Precision: 0.724\n",
      "  Recall: 0.619\n",
      "\n",
      "=== Pair 68/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.462\n",
      "  Dice: 0.618\n",
      "  F1: 0.618\n",
      "  Precision: 0.655\n",
      "  Recall: 0.619\n",
      "\n",
      "=== Pair 69/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.493\n",
      "  Dice: 0.644\n",
      "  F1: 0.644\n",
      "  Precision: 0.676\n",
      "  Recall: 0.641\n",
      "\n",
      "=== Pair 70/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.366\n",
      "  Dice: 0.515\n",
      "  F1: 0.515\n",
      "  Precision: 0.569\n",
      "  Recall: 0.507\n",
      "\n",
      "=== Pair 71/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.367\n",
      "  Dice: 0.509\n",
      "  F1: 0.509\n",
      "  Precision: 0.587\n",
      "  Recall: 0.494\n",
      "\n",
      "=== Pair 72/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.311\n",
      "  Dice: 0.377\n",
      "  F1: 0.377\n",
      "  Precision: 0.861\n",
      "  Recall: 0.382\n",
      "\n",
      "=== Pair 73/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.361\n",
      "  Dice: 0.446\n",
      "  F1: 0.446\n",
      "  Precision: 0.841\n",
      "  Recall: 0.432\n",
      "\n",
      "=== Pair 74/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.483\n",
      "  Dice: 0.630\n",
      "  F1: 0.630\n",
      "  Precision: 0.686\n",
      "  Recall: 0.607\n",
      "\n",
      "=== Pair 75/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.469\n",
      "  Dice: 0.617\n",
      "  F1: 0.617\n",
      "  Precision: 0.664\n",
      "  Recall: 0.600\n",
      "\n",
      "=== Pair 76/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.433\n",
      "  Dice: 0.587\n",
      "  F1: 0.587\n",
      "  Precision: 0.645\n",
      "  Recall: 0.573\n",
      "\n",
      "=== Pair 77/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.487\n",
      "  Dice: 0.639\n",
      "  F1: 0.639\n",
      "  Precision: 0.683\n",
      "  Recall: 0.625\n",
      "\n",
      "=== Pair 78/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.365\n",
      "  Dice: 0.517\n",
      "  F1: 0.517\n",
      "  Precision: 0.576\n",
      "  Recall: 0.505\n",
      "\n",
      "=== Pair 79/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.369\n",
      "  Dice: 0.517\n",
      "  F1: 0.517\n",
      "  Precision: 0.583\n",
      "  Recall: 0.501\n",
      "\n",
      "=== Pair 80/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.342\n",
      "  Dice: 0.483\n",
      "  F1: 0.483\n",
      "  Precision: 0.563\n",
      "  Recall: 0.467\n",
      "\n",
      "=== Pair 81/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.366\n",
      "  Dice: 0.517\n",
      "  F1: 0.517\n",
      "  Precision: 0.605\n",
      "  Recall: 0.503\n",
      "\n",
      "=== Pair 82/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.287\n",
      "  Dice: 0.355\n",
      "  F1: 0.355\n",
      "  Precision: 0.860\n",
      "  Recall: 0.358\n",
      "\n",
      "=== Pair 83/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.354\n",
      "  Dice: 0.433\n",
      "  F1: 0.433\n",
      "  Precision: 0.810\n",
      "  Recall: 0.424\n",
      "\n",
      "=== Pair 84/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.429\n",
      "  Dice: 0.577\n",
      "  F1: 0.577\n",
      "  Precision: 0.624\n",
      "  Recall: 0.565\n",
      "\n",
      "=== Pair 85/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.439\n",
      "  Dice: 0.588\n",
      "  F1: 0.588\n",
      "  Precision: 0.623\n",
      "  Recall: 0.583\n",
      "\n",
      "=== Pair 86/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.461\n",
      "  Dice: 0.614\n",
      "  F1: 0.614\n",
      "  Precision: 0.645\n",
      "  Recall: 0.610\n",
      "\n",
      "=== Pair 87/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.353\n",
      "  Dice: 0.502\n",
      "  F1: 0.502\n",
      "  Precision: 0.567\n",
      "  Recall: 0.495\n",
      "\n",
      "=== Pair 88/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.326\n",
      "  Dice: 0.475\n",
      "  F1: 0.475\n",
      "  Precision: 0.549\n",
      "  Recall: 0.459\n",
      "\n",
      "=== Pair 89/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.391\n",
      "  Dice: 0.534\n",
      "  F1: 0.534\n",
      "  Precision: 0.606\n",
      "  Recall: 0.520\n",
      "\n",
      "=== Pair 90/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.405\n",
      "  Dice: 0.547\n",
      "  F1: 0.547\n",
      "  Precision: 0.648\n",
      "  Recall: 0.524\n",
      "\n",
      "=== Pair 91/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.274\n",
      "  Dice: 0.350\n",
      "  F1: 0.350\n",
      "  Precision: 0.855\n",
      "  Recall: 0.341\n",
      "\n",
      "=== Pair 92/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.299\n",
      "  Dice: 0.393\n",
      "  F1: 0.393\n",
      "  Precision: 0.768\n",
      "  Recall: 0.389\n",
      "\n",
      "=== Pair 93/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.387\n",
      "  Dice: 0.538\n",
      "  F1: 0.538\n",
      "  Precision: 0.569\n",
      "  Recall: 0.536\n",
      "\n",
      "=== Pair 94/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.455\n",
      "  Dice: 0.607\n",
      "  F1: 0.607\n",
      "  Precision: 0.631\n",
      "  Recall: 0.604\n",
      "\n",
      "=== Pair 95/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.379\n",
      "  Dice: 0.522\n",
      "  F1: 0.522\n",
      "  Precision: 0.553\n",
      "  Recall: 0.521\n",
      "\n",
      "=== Pair 96/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.347\n",
      "  Dice: 0.496\n",
      "  F1: 0.496\n",
      "  Precision: 0.600\n",
      "  Recall: 0.473\n",
      "\n",
      "=== Pair 97/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.406\n",
      "  Dice: 0.555\n",
      "  F1: 0.555\n",
      "  Precision: 0.602\n",
      "  Recall: 0.552\n",
      "\n",
      "=== Pair 98/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.381\n",
      "  Dice: 0.525\n",
      "  F1: 0.525\n",
      "  Precision: 0.595\n",
      "  Recall: 0.517\n",
      "\n",
      "=== Pair 99/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.216\n",
      "  Dice: 0.299\n",
      "  F1: 0.299\n",
      "  Precision: 0.807\n",
      "  Recall: 0.294\n",
      "\n",
      "=== Pair 100/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.310\n",
      "  Dice: 0.414\n",
      "  F1: 0.414\n",
      "  Precision: 0.717\n",
      "  Recall: 0.409\n",
      "\n",
      "=== Pair 101/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.345\n",
      "  Dice: 0.498\n",
      "  F1: 0.498\n",
      "  Precision: 0.525\n",
      "  Recall: 0.493\n",
      "\n",
      "=== Pair 102/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.335\n",
      "  Dice: 0.485\n",
      "  F1: 0.485\n",
      "  Precision: 0.510\n",
      "  Recall: 0.478\n",
      "\n",
      "=== Pair 103/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.380\n",
      "  Dice: 0.535\n",
      "  F1: 0.535\n",
      "  Precision: 0.581\n",
      "  Recall: 0.523\n",
      "\n",
      "=== Pair 104/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.382\n",
      "  Dice: 0.535\n",
      "  F1: 0.535\n",
      "  Precision: 0.592\n",
      "  Recall: 0.527\n",
      "\n",
      "=== Pair 105/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.395\n",
      "  Dice: 0.548\n",
      "  F1: 0.548\n",
      "  Precision: 0.636\n",
      "  Recall: 0.528\n",
      "\n",
      "=== Pair 106/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.204\n",
      "  Dice: 0.286\n",
      "  F1: 0.286\n",
      "  Precision: 0.803\n",
      "  Recall: 0.278\n",
      "\n",
      "=== Pair 107/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.323\n",
      "  Dice: 0.447\n",
      "  F1: 0.447\n",
      "  Precision: 0.643\n",
      "  Recall: 0.454\n",
      "\n",
      "=== Pair 108/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.336\n",
      "  Dice: 0.486\n",
      "  F1: 0.486\n",
      "  Precision: 0.527\n",
      "  Recall: 0.481\n",
      "\n",
      "=== Pair 109/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.410\n",
      "  Dice: 0.562\n",
      "  F1: 0.562\n",
      "  Precision: 0.592\n",
      "  Recall: 0.559\n",
      "\n",
      "=== Pair 110/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.363\n",
      "  Dice: 0.513\n",
      "  F1: 0.513\n",
      "  Precision: 0.580\n",
      "  Recall: 0.504\n",
      "\n",
      "=== Pair 111/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.404\n",
      "  Dice: 0.555\n",
      "  F1: 0.555\n",
      "  Precision: 0.630\n",
      "  Recall: 0.541\n",
      "\n",
      "=== Pair 112/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.186\n",
      "  Dice: 0.273\n",
      "  F1: 0.273\n",
      "  Precision: 0.781\n",
      "  Recall: 0.260\n",
      "\n",
      "=== Pair 113/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.292\n",
      "  Dice: 0.424\n",
      "  F1: 0.424\n",
      "  Precision: 0.605\n",
      "  Recall: 0.417\n",
      "\n",
      "=== Pair 114/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.292\n",
      "  Dice: 0.431\n",
      "  F1: 0.431\n",
      "  Precision: 0.515\n",
      "  Recall: 0.433\n",
      "\n",
      "=== Pair 115/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.399\n",
      "  Dice: 0.557\n",
      "  F1: 0.557\n",
      "  Precision: 0.595\n",
      "  Recall: 0.548\n",
      "\n",
      "=== Pair 116/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.358\n",
      "  Dice: 0.508\n",
      "  F1: 0.508\n",
      "  Precision: 0.581\n",
      "  Recall: 0.502\n",
      "\n",
      "=== Pair 117/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.223\n",
      "  Dice: 0.277\n",
      "  F1: 0.277\n",
      "  Precision: 0.845\n",
      "  Recall: 0.279\n",
      "\n",
      "=== Pair 118/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.145\n",
      "  Dice: 0.178\n",
      "  F1: 0.178\n",
      "  Precision: 0.961\n",
      "  Recall: 0.163\n",
      "\n",
      "=== Pair 119/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.378\n",
      "  Dice: 0.512\n",
      "  F1: 0.512\n",
      "  Precision: 0.609\n",
      "  Recall: 0.517\n",
      "\n",
      "=== Pair 120/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.445\n",
      "  Dice: 0.583\n",
      "  F1: 0.583\n",
      "  Precision: 0.634\n",
      "  Recall: 0.606\n",
      "\n",
      "=== Pair 121/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.389\n",
      "  Dice: 0.453\n",
      "  F1: 0.453\n",
      "  Precision: 0.840\n",
      "  Recall: 0.444\n",
      "\n",
      "=== Pair 122/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.131\n",
      "  Dice: 0.166\n",
      "  F1: 0.166\n",
      "  Precision: 0.947\n",
      "  Recall: 0.152\n",
      "\n",
      "=== Pair 123/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.243\n",
      "  Dice: 0.302\n",
      "  F1: 0.302\n",
      "  Precision: 0.892\n",
      "  Recall: 0.287\n",
      "\n",
      "=== Pair 124/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.428\n",
      "  Dice: 0.574\n",
      "  F1: 0.574\n",
      "  Precision: 0.588\n",
      "  Recall: 0.587\n",
      "\n",
      "=== Pair 125/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.362\n",
      "  Dice: 0.484\n",
      "  F1: 0.484\n",
      "  Precision: 0.677\n",
      "  Recall: 0.487\n",
      "\n",
      "=== Pair 126/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.230\n",
      "  Dice: 0.329\n",
      "  F1: 0.329\n",
      "  Precision: 0.760\n",
      "  Recall: 0.312\n",
      "\n",
      "=== Pair 127/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.308\n",
      "  Dice: 0.359\n",
      "  F1: 0.359\n",
      "  Precision: 0.941\n",
      "  Recall: 0.340\n",
      "\n",
      "=== Pair 128/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.408\n",
      "  Dice: 0.567\n",
      "  F1: 0.567\n",
      "  Precision: 0.581\n",
      "  Recall: 0.576\n",
      "\n",
      "=== Pair 129/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.393\n",
      "  Dice: 0.543\n",
      "  F1: 0.543\n",
      "  Precision: 0.561\n",
      "  Recall: 0.553\n",
      "\n",
      "=== Pair 130/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.381\n",
      "  Dice: 0.536\n",
      "  F1: 0.536\n",
      "  Precision: 0.552\n",
      "  Recall: 0.547\n",
      "\n",
      "=== Pair 131/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.466\n",
      "  Dice: 0.612\n",
      "  F1: 0.612\n",
      "  Precision: 0.645\n",
      "  Recall: 0.621\n",
      "\n",
      "=== Pair 132/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.416\n",
      "  Dice: 0.571\n",
      "  F1: 0.571\n",
      "  Precision: 0.602\n",
      "  Recall: 0.578\n",
      "\n",
      "=== Pair 133/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.443\n",
      "  Dice: 0.582\n",
      "  F1: 0.582\n",
      "  Precision: 0.626\n",
      "  Recall: 0.587\n",
      "\n",
      "=== Pair 134/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.393\n",
      "  Dice: 0.512\n",
      "  F1: 0.512\n",
      "  Precision: 0.711\n",
      "  Recall: 0.504\n",
      "\n",
      "=== Pair 135/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.277\n",
      "  Dice: 0.373\n",
      "  F1: 0.373\n",
      "  Precision: 0.792\n",
      "  Recall: 0.359\n",
      "\n",
      "=== Pair 136/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.278\n",
      "  Dice: 0.345\n",
      "  F1: 0.345\n",
      "  Precision: 0.901\n",
      "  Recall: 0.320\n",
      "\n",
      "=== Pair 137/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.421\n",
      "  Dice: 0.578\n",
      "  F1: 0.578\n",
      "  Precision: 0.597\n",
      "  Recall: 0.586\n",
      "\n",
      "=== Pair 138/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.397\n",
      "  Dice: 0.553\n",
      "  F1: 0.553\n",
      "  Precision: 0.575\n",
      "  Recall: 0.564\n",
      "\n",
      "=== Pair 139/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.391\n",
      "  Dice: 0.540\n",
      "  F1: 0.540\n",
      "  Precision: 0.555\n",
      "  Recall: 0.552\n",
      "\n",
      "=== Pair 140/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.380\n",
      "  Dice: 0.530\n",
      "  F1: 0.530\n",
      "  Precision: 0.550\n",
      "  Recall: 0.548\n",
      "\n",
      "=== Pair 141/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.396\n",
      "  Dice: 0.557\n",
      "  F1: 0.557\n",
      "  Precision: 0.570\n",
      "  Recall: 0.564\n",
      "\n",
      "=== Pair 142/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.413\n",
      "  Dice: 0.573\n",
      "  F1: 0.573\n",
      "  Precision: 0.602\n",
      "  Recall: 0.578\n",
      "\n",
      "=== Pair 143/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.368\n",
      "  Dice: 0.526\n",
      "  F1: 0.526\n",
      "  Precision: 0.545\n",
      "  Recall: 0.534\n",
      "\n",
      "=== Pair 144/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.344\n",
      "  Dice: 0.494\n",
      "  F1: 0.494\n",
      "  Precision: 0.518\n",
      "  Recall: 0.502\n",
      "\n",
      "=== Pair 145/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.372\n",
      "  Dice: 0.510\n",
      "  F1: 0.510\n",
      "  Precision: 0.537\n",
      "  Recall: 0.517\n",
      "\n",
      "=== Pair 146/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.397\n",
      "  Dice: 0.545\n",
      "  F1: 0.545\n",
      "  Precision: 0.563\n",
      "  Recall: 0.556\n",
      "\n",
      "=== Pair 147/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.380\n",
      "  Dice: 0.515\n",
      "  F1: 0.515\n",
      "  Precision: 0.539\n",
      "  Recall: 0.523\n",
      "\n",
      "=== Pair 148/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.383\n",
      "  Dice: 0.539\n",
      "  F1: 0.539\n",
      "  Precision: 0.556\n",
      "  Recall: 0.550\n",
      "\n",
      "=== Pair 149/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.372\n",
      "  Dice: 0.524\n",
      "  F1: 0.524\n",
      "  Precision: 0.549\n",
      "  Recall: 0.539\n",
      "\n",
      "=== Pair 150/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.341\n",
      "  Dice: 0.483\n",
      "  F1: 0.483\n",
      "  Precision: 0.551\n",
      "  Recall: 0.499\n",
      "\n",
      "=== Pair 151/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.387\n",
      "  Dice: 0.538\n",
      "  F1: 0.538\n",
      "  Precision: 0.586\n",
      "  Recall: 0.540\n",
      "\n",
      "=== Pair 152/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.435\n",
      "  Dice: 0.576\n",
      "  F1: 0.576\n",
      "  Precision: 0.610\n",
      "  Recall: 0.579\n",
      "\n",
      "=== Pair 153/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.482\n",
      "  Dice: 0.633\n",
      "  F1: 0.633\n",
      "  Precision: 0.643\n",
      "  Recall: 0.640\n",
      "\n",
      "=== Pair 154/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.326\n",
      "  Dice: 0.472\n",
      "  F1: 0.472\n",
      "  Precision: 0.504\n",
      "  Recall: 0.477\n",
      "\n",
      "=== Pair 155/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.398\n",
      "  Dice: 0.550\n",
      "  F1: 0.550\n",
      "  Precision: 0.575\n",
      "  Recall: 0.556\n",
      "\n",
      "=== Pair 156/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.355\n",
      "  Dice: 0.507\n",
      "  F1: 0.507\n",
      "  Precision: 0.518\n",
      "  Recall: 0.522\n",
      "\n",
      "=== Pair 157/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.381\n",
      "  Dice: 0.536\n",
      "  F1: 0.536\n",
      "  Precision: 0.552\n",
      "  Recall: 0.548\n",
      "\n",
      "=== Pair 158/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.388\n",
      "  Dice: 0.541\n",
      "  F1: 0.541\n",
      "  Precision: 0.572\n",
      "  Recall: 0.552\n",
      "\n",
      "=== Pair 159/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.386\n",
      "  Dice: 0.537\n",
      "  F1: 0.537\n",
      "  Precision: 0.588\n",
      "  Recall: 0.552\n",
      "\n",
      "=== Pair 160/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.403\n",
      "  Dice: 0.561\n",
      "  F1: 0.561\n",
      "  Precision: 0.601\n",
      "  Recall: 0.564\n",
      "\n",
      "=== Pair 161/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.526\n",
      "  Dice: 0.675\n",
      "  F1: 0.675\n",
      "  Precision: 0.696\n",
      "  Recall: 0.677\n",
      "\n",
      "=== Pair 162/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.374\n",
      "  Dice: 0.517\n",
      "  F1: 0.517\n",
      "  Precision: 0.547\n",
      "  Recall: 0.526\n",
      "\n",
      "=== Pair 163/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.401\n",
      "  Dice: 0.556\n",
      "  F1: 0.556\n",
      "  Precision: 0.590\n",
      "  Recall: 0.563\n",
      "\n",
      "=== Pair 164/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.428\n",
      "  Dice: 0.582\n",
      "  F1: 0.582\n",
      "  Precision: 0.603\n",
      "  Recall: 0.589\n",
      "\n",
      "=== Pair 165/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.383\n",
      "  Dice: 0.539\n",
      "  F1: 0.539\n",
      "  Precision: 0.564\n",
      "  Recall: 0.550\n",
      "\n",
      "=== Pair 166/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.344\n",
      "  Dice: 0.498\n",
      "  F1: 0.498\n",
      "  Precision: 0.516\n",
      "  Recall: 0.511\n",
      "\n",
      "=== Pair 167/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.388\n",
      "  Dice: 0.534\n",
      "  F1: 0.534\n",
      "  Precision: 0.566\n",
      "  Recall: 0.548\n",
      "\n",
      "=== Pair 168/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.353\n",
      "  Dice: 0.505\n",
      "  F1: 0.505\n",
      "  Precision: 0.550\n",
      "  Recall: 0.516\n",
      "\n",
      "=== Pair 169/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.381\n",
      "  Dice: 0.536\n",
      "  F1: 0.536\n",
      "  Precision: 0.553\n",
      "  Recall: 0.543\n",
      "\n",
      "=== Pair 170/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.482\n",
      "  Dice: 0.595\n",
      "  F1: 0.595\n",
      "  Precision: 0.701\n",
      "  Recall: 0.600\n",
      "\n",
      "=== Pair 171/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.467\n",
      "  Dice: 0.620\n",
      "  F1: 0.620\n",
      "  Precision: 0.639\n",
      "  Recall: 0.624\n",
      "\n",
      "=== Pair 172/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.475\n",
      "  Dice: 0.633\n",
      "  F1: 0.633\n",
      "  Precision: 0.644\n",
      "  Recall: 0.640\n",
      "\n",
      "=== Pair 173/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.385\n",
      "  Dice: 0.537\n",
      "  F1: 0.537\n",
      "  Precision: 0.549\n",
      "  Recall: 0.548\n",
      "\n",
      "=== Pair 174/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.362\n",
      "  Dice: 0.515\n",
      "  F1: 0.515\n",
      "  Precision: 0.536\n",
      "  Recall: 0.526\n",
      "\n",
      "=== Pair 175/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.311\n",
      "  Dice: 0.462\n",
      "  F1: 0.462\n",
      "  Precision: 0.482\n",
      "  Recall: 0.479\n",
      "\n",
      "=== Pair 176/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.317\n",
      "  Dice: 0.469\n",
      "  F1: 0.469\n",
      "  Precision: 0.488\n",
      "  Recall: 0.484\n",
      "\n",
      "=== Pair 177/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.360\n",
      "  Dice: 0.515\n",
      "  F1: 0.515\n",
      "  Precision: 0.541\n",
      "  Recall: 0.531\n",
      "\n",
      "=== Pair 178/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.352\n",
      "  Dice: 0.478\n",
      "  F1: 0.478\n",
      "  Precision: 0.573\n",
      "  Recall: 0.476\n",
      "\n",
      "=== Pair 179/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.474\n",
      "  Dice: 0.626\n",
      "  F1: 0.626\n",
      "  Precision: 0.650\n",
      "  Recall: 0.635\n",
      "\n",
      "=== Pair 180/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.436\n",
      "  Dice: 0.591\n",
      "  F1: 0.591\n",
      "  Precision: 0.623\n",
      "  Recall: 0.599\n",
      "\n",
      "=== Pair 181/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.509\n",
      "  Dice: 0.651\n",
      "  F1: 0.651\n",
      "  Precision: 0.657\n",
      "  Recall: 0.657\n",
      "\n",
      "=== Pair 182/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.360\n",
      "  Dice: 0.509\n",
      "  F1: 0.509\n",
      "  Precision: 0.527\n",
      "  Recall: 0.525\n",
      "\n",
      "=== Pair 183/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.340\n",
      "  Dice: 0.483\n",
      "  F1: 0.483\n",
      "  Precision: 0.544\n",
      "  Recall: 0.495\n",
      "\n",
      "=== Pair 184/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.348\n",
      "  Dice: 0.484\n",
      "  F1: 0.484\n",
      "  Precision: 0.583\n",
      "  Recall: 0.489\n",
      "\n",
      "=== Pair 185/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.427\n",
      "  Dice: 0.557\n",
      "  F1: 0.557\n",
      "  Precision: 0.612\n",
      "  Recall: 0.553\n",
      "\n",
      "=== Pair 186/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.524\n",
      "  Dice: 0.659\n",
      "  F1: 0.659\n",
      "  Precision: 0.695\n",
      "  Recall: 0.660\n",
      "\n",
      "=== Pair 187/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.420\n",
      "  Dice: 0.566\n",
      "  F1: 0.566\n",
      "  Precision: 0.610\n",
      "  Recall: 0.579\n",
      "\n",
      "=== Pair 188/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.468\n",
      "  Dice: 0.622\n",
      "  F1: 0.622\n",
      "  Precision: 0.644\n",
      "  Recall: 0.629\n",
      "\n",
      "=== Pair 189/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.486\n",
      "  Dice: 0.628\n",
      "  F1: 0.628\n",
      "  Precision: 0.644\n",
      "  Recall: 0.635\n",
      "\n",
      "=== Pair 190/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.347\n",
      "  Dice: 0.499\n",
      "  F1: 0.499\n",
      "  Precision: 0.529\n",
      "  Recall: 0.513\n",
      "\n",
      "=== Pair 191/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.328\n",
      "  Dice: 0.460\n",
      "  F1: 0.460\n",
      "  Precision: 0.560\n",
      "  Recall: 0.461\n",
      "\n",
      "=== Pair 192/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.456\n",
      "  Dice: 0.598\n",
      "  F1: 0.598\n",
      "  Precision: 0.623\n",
      "  Recall: 0.608\n",
      "\n",
      "=== Pair 193/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.462\n",
      "  Dice: 0.606\n",
      "  F1: 0.606\n",
      "  Precision: 0.635\n",
      "  Recall: 0.614\n",
      "\n",
      "=== Pair 194/196 ===\n",
      "Mean metrics for this pair:\n",
      "  IoU: 0.500\n",
      "  Dice: 0.630\n",
      "  F1: 0.630\n",
      "  Precision: 0.642\n",
      "  Recall: 0.635\n",
      "\n",
      "=== Pair 195/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.443\n",
      "  Dice: 0.513\n",
      "  F1: 0.513\n",
      "  Precision: 0.838\n",
      "  Recall: 0.499\n",
      "\n",
      "=== Pair 196/196 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics for this pair:\n",
      "  IoU: 0.275\n",
      "  Dice: 0.326\n",
      "  F1: 0.326\n",
      "  Precision: 0.858\n",
      "  Recall: 0.301\n",
      "\n",
      "=== Overall Summary Across All Pairs ===\n",
      "Average IoU: 0.403\n",
      "Median IoU: 0.398\n",
      "Average Dice: 0.538\n",
      "Median Dice: 0.546\n",
      "Average F1: 0.538\n",
      "Median F1: 0.546\n",
      "Average Precision: 0.653\n",
      "Median Precision: 0.639\n",
      "Average Recall: 0.537\n",
      "Median Recall: 0.550\n",
      "Saved results for disaster 'earthquake' to C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\\multiclass\\earthquake\n",
      "Saved results for disaster 'volcano' to C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\\multiclass\\volcano\n",
      "\n",
      "Saved all results to: C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\\multiclass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweta\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#multi class\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Model setup\n",
    "device = config.device\n",
    "G.eval()\n",
    "\n",
    "disaster_types = ['earthquake', 'flood', 'hurricane', 'fire', 'tsunami', 'volcano']\n",
    "\n",
    "# Disaster label inference\n",
    "def infer_disaster_type(filename):\n",
    "    for d in disaster_types:\n",
    "        if d in filename.lower():\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "transform_rgb = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "transform_gray = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def tensor_to_pil(tensor):\n",
    "    \"\"\"\n",
    "    Convert a normalized tensor (C,H,W) with values in [-1,1] to a PIL RGB image.\n",
    "    \"\"\"\n",
    "    tensor = tensor.squeeze(0).cpu()  # Remove batch dim, move to CPU\n",
    "    tensor = (tensor * 0.5) + 0.5     # Denormalize from [-1,1] to [0,1]\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    np_img = tensor.permute(1, 2, 0).numpy() * 255\n",
    "    np_img = np_img.astype(np.uint8)\n",
    "    return Image.fromarray(np_img)\n",
    "'''\n",
    "# Multiclass SAR damage mask\n",
    "def SAR_damage_mask_multiclass_merged(pre_optical_img, post_sar_img):\n",
    "    def optical_to_sar_like(img):\n",
    "        img = img.convert('L')\n",
    "        img = ImageOps.autocontrast(img, cutoff=2)\n",
    "        return img\n",
    "\n",
    "    pre_sar_like = optical_to_sar_like(pre_optical_img)\n",
    "    post_sar = post_sar_img.convert('L')\n",
    "\n",
    "    pre_tensor = transform_gray(pre_sar_like).to(device).squeeze(0)\n",
    "    post_tensor = transform_gray(post_sar).to(device).squeeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        diff = torch.abs(post_tensor - pre_tensor)  # shape (H, W)\n",
    "        diff_smoothed = F.avg_pool2d(diff.unsqueeze(0).unsqueeze(0), kernel_size=3, stride=1, padding=1).squeeze()\n",
    "\n",
    "        # Normalize diff to [0,1]\n",
    "        diff_min, diff_max = diff_smoothed.min(), diff_smoothed.max()\n",
    "        diff_norm = (diff_smoothed - diff_min) / (diff_max - diff_min + 1e-8)\n",
    "\n",
    "        # Thresholds to classify damage severity (excluding background/no damage separation)\n",
    "        thresholds = [0.1, 0.25, 0.5]  # tune these empirically\n",
    "\n",
    "        mask = torch.zeros_like(diff_norm, dtype=torch.long)  # 0 = no damage (including background)\n",
    "\n",
    "        mask = torch.where((diff_norm >= thresholds[0]) & (diff_norm < thresholds[1]), 1, mask)  # Minor damage\n",
    "        mask = torch.where((diff_norm >= thresholds[1]) & (diff_norm < thresholds[2]), 2, mask)  # Major damage\n",
    "        mask = torch.where(diff_norm >= thresholds[2], 3, mask)  # Destroyed\n",
    "\n",
    "    return mask.cpu()  # (H, W) tensor with int labels 0-3\n",
    "    '''\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_opening, binary_closing\n",
    "\n",
    "def clean_multiclass_mask(mask_np, min_region_size=20):\n",
    "    cleaned_mask = np.zeros_like(mask_np)\n",
    "    for cls in range(1, 4):  # Skip 0 (no damage)\n",
    "        binary = (mask_np == cls)\n",
    "        binary = binary_opening(binary, structure=np.ones((3,3)))\n",
    "        binary = binary_closing(binary, structure=np.ones((3,3)))\n",
    "        cleaned_mask[binary] = cls\n",
    "    return cleaned_mask\n",
    "\n",
    "def SAR_damage_mask_multiclass_merged(pre_optical_img, post_sar_img):\n",
    "    def optical_to_sar_like(img):\n",
    "        img = img.convert('L')\n",
    "        img = ImageOps.autocontrast(img, cutoff=2)\n",
    "        return img\n",
    "\n",
    "    pre_sar_like = optical_to_sar_like(pre_optical_img)\n",
    "    post_sar = post_sar_img.convert('L')\n",
    "\n",
    "    pre_tensor = transform_gray(pre_sar_like).to(device).squeeze(0)\n",
    "    post_tensor = transform_gray(post_sar).to(device).squeeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        diff = torch.abs(post_tensor - pre_tensor)  # shape (H, W)\n",
    "        diff_smoothed = F.avg_pool2d(diff.unsqueeze(0).unsqueeze(0), kernel_size=5, stride=1, padding=2).squeeze()\n",
    "\n",
    "        # Normalize diff to [0,1]\n",
    "        diff_min, diff_max = diff_smoothed.min(), diff_smoothed.max()\n",
    "        diff_norm = (diff_smoothed - diff_min) / (diff_max - diff_min + 1e-8)\n",
    "\n",
    "        # Improved thresholds (more spaced out)\n",
    "        thresholds = [0.08, 0.22, 0.45]  # You can grid search/tune these\n",
    "\n",
    "        # Initial multiclass mask (0 = no damage, 1 = minor, 2 = major, 3 = destroyed)\n",
    "        mask = torch.zeros_like(diff_norm, dtype=torch.long)\n",
    "        mask = torch.where((diff_norm >= thresholds[0]) & (diff_norm < thresholds[1]), 1, mask)  # Minor\n",
    "        mask = torch.where((diff_norm >= thresholds[1]) & (diff_norm < thresholds[2]), 2, mask)  # Major\n",
    "        mask = torch.where(diff_norm >= thresholds[2], 3, mask)  # Destroyed\n",
    "\n",
    "    # Post-process: remove specks and smooth classes\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    cleaned = clean_multiclass_mask(mask_np)\n",
    "\n",
    "    return torch.from_numpy(cleaned).long()\n",
    "\n",
    "\n",
    "# Metric calculation with weighted average for multiclass\n",
    "def compute_mask_metrics(pred_mask, true_mask):\n",
    "    pred = pred_mask.flatten().cpu().numpy().astype(int)\n",
    "    true = true_mask.flatten().cpu().numpy().astype(int)\n",
    "    return {\n",
    "        'IoU': jaccard_score(true, pred, average='weighted'),\n",
    "        'Dice': f1_score(true, pred, average='weighted'),\n",
    "        'F1': f1_score(true, pred, average='weighted'),\n",
    "        'Precision': precision_score(true, pred, average='weighted'),\n",
    "        'Recall': recall_score(true, pred, average='weighted')\n",
    "    }\n",
    "\n",
    "# 95% Confidence Interval function\n",
    "def compute_ci(arr):\n",
    "    mean = np.mean(arr)\n",
    "    std_err = np.std(arr) / np.sqrt(len(arr))\n",
    "    return (mean - 1.96 * std_err, mean + 1.96 * std_err)\n",
    "\n",
    "# Define categorical colormap for visualization of multiclass masks\n",
    "damage_colors = ['black', 'blue', 'yellow', 'red']  # for classes 0 to 3\n",
    "cmap = mcolors.ListedColormap(damage_colors)\n",
    "norm = mcolors.BoundaryNorm(boundaries=[-0.5,0.5,1.5,2.5,3.5], ncolors=len(damage_colors))\n",
    "\n",
    "# Get all pre-post pairs\n",
    "low_income = ['congo', 'haiti']\n",
    "pre_event_dir = r\"C:\\Users\\sweta\\Downloads\\pre-event\\pre-event_wo_ukraine_myanmar_mexico\"\n",
    "post_event_dir = r\"C:\\Users\\sweta\\Downloads\\post-event\\post-event\"\n",
    "all_pre_files = os.listdir(pre_event_dir)\n",
    "filtered_pre_files = [f for f in all_pre_files if any(country.lower() in f.lower() for country in low_income)]\n",
    "expected_post_files = [f.replace('_pre_disaster', '_post_disaster') for f in filtered_pre_files]\n",
    "all_post_files = os.listdir(post_event_dir)\n",
    "pairs = [\n",
    "    (os.path.join(pre_event_dir, pre), os.path.join(post_event_dir, post))\n",
    "    for pre, post in zip(filtered_pre_files, expected_post_files)\n",
    "    if post in all_post_files\n",
    "]\n",
    "\n",
    "# Output directories setup - NEW multiclass folder inside lic_results\n",
    "base_results_dir = r\"C:\\Users\\sweta\\anaconda_projects\\non-trivial\\evaluation_bias\\lic_results\"\n",
    "output_dir = os.path.join(base_results_dir, \"multiclass\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "disaster_output_dirs = {}\n",
    "for d in disaster_types:\n",
    "    dir_path = os.path.join(output_dir, d)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    disaster_output_dirs[d] = dir_path\n",
    "\n",
    "# Evaluation loop\n",
    "all_pair_metrics = []\n",
    "disaster_type_metrics = {d: [] for d in disaster_types}\n",
    "\n",
    "for pair_idx, (pre_path, post_path) in enumerate(pairs):\n",
    "    print(f\"\\n=== Pair {pair_idx+1}/{len(pairs)} ===\")\n",
    "    pre_img_full = Image.open(pre_path).convert('RGB')\n",
    "    post_img_full = Image.open(post_path).convert('RGB')\n",
    "\n",
    "    tile_size = 256\n",
    "    width, height = pre_img_full.size\n",
    "    tiles = []\n",
    "\n",
    "    for top in range(0, height, tile_size):\n",
    "        for left in range(0, width, tile_size):\n",
    "            box = (left, top, left + tile_size, top + tile_size)\n",
    "            if box[2] <= width and box[3] <= height:\n",
    "                pre_tile = pre_img_full.crop(box)\n",
    "                post_tile = post_img_full.crop(box)\n",
    "                tiles.append((pre_tile, post_tile))\n",
    "\n",
    "    tile_metrics = []\n",
    "\n",
    "    for idx, (pre_img, post_img) in enumerate(tiles):\n",
    "        input_tensor = transform_rgb(pre_img).unsqueeze(0).to(device)\n",
    "        post_resized = post_img.resize((256, 256))\n",
    "\n",
    "        inferred_type = infer_disaster_type(pre_path)\n",
    "        if inferred_type is None:\n",
    "            print(f\"Unknown disaster type for file: {pre_path}\")\n",
    "            continue\n",
    "\n",
    "        disaster_idx = disaster_types.index(inferred_type)\n",
    "        disaster_label = torch.tensor([[disaster_idx]], device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_post, pred_mask = G(input_tensor, disaster_label)\n",
    "        # Use multiclass mask function here\n",
    "        actual_mask = SAR_damage_mask_multiclass_merged(pre_img, post_resized)\n",
    "        fake_post_img = tensor_to_pil(fake_post)\n",
    "        pred_mask = SAR_damage_mask_multiclass_merged(pre_img, fake_post_img)\n",
    "\n",
    "        metrics = compute_mask_metrics(pred_mask, actual_mask)\n",
    "        tile_metrics.append(metrics)\n",
    "\n",
    "        # Save visualization every 10th tile\n",
    "        if idx % 10 == 0:\n",
    "            vis_dir = os.path.join(disaster_output_dirs[inferred_type], \"visualizations\")\n",
    "            os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "            axs[0].imshow(pre_img)\n",
    "            axs[0].set_title(\"Pre-disaster\")\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            axs[1].imshow(post_img)\n",
    "            axs[1].set_title(\"Post-disaster (True)\")\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            axs[2].imshow(fake_post_img)\n",
    "            axs[2].set_title(\"Fake Post (Generated)\")\n",
    "            axs[2].axis('off')\n",
    "\n",
    "            # Show predicted damage mask with categorical colors\n",
    "            axs[3].imshow(pred_mask.cpu(), cmap=cmap, norm=norm)\n",
    "            axs[3].set_title(\"Predicted Damage Mask\")\n",
    "            axs[3].axis('off')\n",
    "\n",
    "            plt.suptitle(f\"Pair {pair_idx+1}, Tile {idx} ({inferred_type})\")\n",
    "            save_path = os.path.join(vis_dir, f\"pair{pair_idx+1}_tile{idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'IoU': np.mean([m['IoU'] for m in tile_metrics]),\n",
    "        'Dice': np.mean([m['Dice'] for m in tile_metrics]),\n",
    "        'F1': np.mean([m['F1'] for m in tile_metrics]),\n",
    "        'Precision': np.mean([m['Precision'] for m in tile_metrics]),\n",
    "        'Recall': np.mean([m['Recall'] for m in tile_metrics]),\n",
    "    }\n",
    "    all_pair_metrics.append({\n",
    "        'pair': (os.path.basename(pre_path), os.path.basename(post_path)),\n",
    "        'metrics': mean_metrics\n",
    "    })\n",
    "    disaster_type_metrics[inferred_type].append(mean_metrics)\n",
    "\n",
    "    print(\"Mean metrics for this pair:\")\n",
    "    for k, v in mean_metrics.items():\n",
    "        print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "# Overall stats\n",
    "print(\"\\n=== Overall Summary Across All Pairs ===\")\n",
    "all_iou = [m['metrics']['IoU'] for m in all_pair_metrics]\n",
    "all_dice = [m['metrics']['Dice'] for m in all_pair_metrics]\n",
    "all_f1 = [m['metrics']['F1'] for m in all_pair_metrics]\n",
    "all_prec = [m['metrics']['Precision'] for m in all_pair_metrics]\n",
    "all_rec = [m['metrics']['Recall'] for m in all_pair_metrics]\n",
    "\n",
    "print(f\"Average IoU: {np.mean(all_iou):.3f}\")\n",
    "print(f\"Median IoU: {np.median(all_iou):.3f}\")\n",
    "print(f\"Average Dice: {np.mean(all_dice):.3f}\")\n",
    "print(f\"Median Dice: {np.median(all_dice):.3f}\")\n",
    "print(f\"Average F1: {np.mean(all_f1):.3f}\")\n",
    "print(f\"Median F1: {np.median(all_f1):.3f}\")\n",
    "print(f\"Average Precision: {np.mean(all_prec):.3f}\")\n",
    "print(f\"Median Precision: {np.median(all_prec):.3f}\")\n",
    "print(f\"Average Recall: {np.mean(all_rec):.3f}\")\n",
    "print(f\"Median Recall: {np.median(all_rec):.3f}\")\n",
    "\n",
    "# Save global results\n",
    "with open(os.path.join(output_dir, \"per_pair_metrics.json\"), \"w\") as f:\n",
    "    json.dump(all_pair_metrics, f, indent=2)\n",
    "\n",
    "summary_stats = {\n",
    "    'Average IoU': float(np.mean(all_iou)),\n",
    "    'Median IoU': float(np.median(all_iou)),\n",
    "    '95% CI IoU': list(compute_ci(all_iou)),\n",
    "\n",
    "    'Average Dice': float(np.mean(all_dice)),\n",
    "    'Median Dice': float(np.median(all_dice)),\n",
    "    '95% CI Dice': list(compute_ci(all_dice)),\n",
    "\n",
    "    'Average F1': float(np.mean(all_f1)),\n",
    "    'Median F1': float(np.median(all_f1)),\n",
    "    '95% CI F1': list(compute_ci(all_f1)),\n",
    "\n",
    "    'Average Precision': float(np.mean(all_prec)),\n",
    "    'Median Precision': float(np.median(all_prec)),\n",
    "    '95% CI Precision': list(compute_ci(all_prec)),\n",
    "\n",
    "    'Average Recall': float(np.mean(all_rec)),\n",
    "    'Median Recall': float(np.median(all_rec)),\n",
    "    '95% CI Recall': list(compute_ci(all_rec)),\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, \"summary_stats.json\"), \"w\") as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "# Save results per disaster type\n",
    "for d in disaster_types:\n",
    "    metrics_list = disaster_type_metrics[d]\n",
    "    if not metrics_list:\n",
    "        continue  # skip if no data for this disaster\n",
    "\n",
    "    iou_vals = [m['IoU'] for m in metrics_list]\n",
    "    dice_vals = [m['Dice'] for m in metrics_list]\n",
    "    f1_vals = [m['F1'] for m in metrics_list]\n",
    "    prec_vals = [m['Precision'] for m in metrics_list]\n",
    "    rec_vals = [m['Recall'] for m in metrics_list]\n",
    "\n",
    "    summary = {\n",
    "        'Average IoU': float(np.mean(iou_vals)),\n",
    "        'Median IoU': float(np.median(iou_vals)),\n",
    "        '95% CI IoU': list(compute_ci(iou_vals)),\n",
    "\n",
    "        'Average Dice': float(np.mean(dice_vals)),\n",
    "        'Median Dice': float(np.median(dice_vals)),\n",
    "        '95% CI Dice': list(compute_ci(dice_vals)),\n",
    "\n",
    "        'Average F1': float(np.mean(f1_vals)),\n",
    "        'Median F1': float(np.median(f1_vals)),\n",
    "        '95% CI F1': list(compute_ci(f1_vals)),\n",
    "\n",
    "        'Average Precision': float(np.mean(prec_vals)),\n",
    "        'Median Precision': float(np.median(prec_vals)),\n",
    "        '95% CI Precision': list(compute_ci(prec_vals)),\n",
    "\n",
    "        'Average Recall': float(np.mean(rec_vals)),\n",
    "        'Median Recall': float(np.median(rec_vals)),\n",
    "        '95% CI Recall': list(compute_ci(rec_vals)),\n",
    "    }\n",
    "\n",
    "    per_pair_path = os.path.join(disaster_output_dirs[d], f\"per_pair_metrics_{d}.json\")\n",
    "    summary_path = os.path.join(disaster_output_dirs[d], f\"summary_stats_{d}.json\")\n",
    "\n",
    "    disaster_pairs = [p for p in all_pair_metrics if infer_disaster_type(p['pair'][0]) == d]\n",
    "\n",
    "    with open(per_pair_path, 'w') as f:\n",
    "        json.dump(disaster_pairs, f, indent=2)\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"Saved results for disaster '{d}' to {disaster_output_dirs[d]}\")\n",
    "\n",
    "print(f\"\\nSaved all results to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7e154-3f36-4cdb-90e5-e63646debc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
